---
output:
  pdf_document: 
    fig_width: 6
    fig_height: 4
  html_document: default
editor_options: 
  chunk_output_type: console
---

# Course Practical Assignment - 3rd Deliverable (maig del 2019)
## *Josep Clotet Ginovart*
## *Eric Martin Obispo*

# Bank client data
## Description of input variables:

  1. age (numeric)
  2. job : type of job (categorical: 'admin', 'blue-collar', 'entrepreneur', 'housemaid', 'management', 'retired', 'self-employed', 'services', 'student', 'technician', 'unemployed', 'unknown')
  3. marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)
  4. education (categorical:'basic.4y', 'basic.6y', 'basic.9y', 'high.school', 'illiterate', 'professional.course', 'university.degree', 'unknown')
  5. default: has credit in default? (categorical: 'no','yes','unknown')
  6. housing: has housing loan? (categorical: 'no','yes','unknown')
  7. loan: has personal loan? (categorical: 'no','yes','unknown')# related with the last contact of the current campaign:
  8. contact: contact communication type (categorical:'cellular','telephone')
  9. month: last contact month of year (categorical: 'jan', 'feb', 'mar',..., 'nov', 'dec')
  10. day_of_week: last contact day of the week (categorical:'mon','tue','wed','thu','fri')
  11. duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.
  12. campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)
  13. pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)
  14. previous: number of contacts performed before this campaign and for this client (numeric)
  15. poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')# social and economic context attributes
  16. emp.var.rate: employment variation rate - quarterly indicator (numeric)
  17. cons.price.idx: consumer price index - monthly indicator (numeric)
  18. cons.conf.idx: consumer confidence index - monthly indicator (numeric)
  19. euribor3m: euribor 3 month rate - daily indicator (numeric)
  20. nr.employed: number of employees - quarterly indicator (numeric)
  21. y - has the client subscribed a term deposit? (binary: 'yes','no')

# Loading packages:
```{r, include=FALSE}
# Required Packages: to be increased over the course
requiredPackages <- c("car","knitr","ggplot2","FactoMineR","missMDA","mvoutlier","chemometrics", "factoextra", "MASS", "effects", "ROCR")
missingPackages <- requiredPackages[!(requiredPackages %in% installed.packages()[,"Package"])]

if(length(missingPackages)) install.packages(missingPackages)
lapply(requiredPackages, require, character.only = TRUE)

```

# Load validated data from Deliverable 1:
```{r}
#invisible() prevent hte output in console of the function
dirwd<-"D:/Users/Usuari/Documents/ADEIpractica"
#dirwd<-"//pax/perfils/1173408.CR/Downloads/deliverable"
#dirwd<-"D:/Documents/GitHub/ADEI"
setwd(dirwd)

load( paste0(dirwd, "/bank-additional/Bank5000_validated.RData") )
summary(df)
```

# Work and test samples division
```{r}
set.seed(69)
sam<-sample(1:nrow(df), 0.75*nrow(df)) #random sample without replacement

dfw<-df[sam,] #work75%
dft<-df[-sam,] #test25%
```

# Variables numeriques explicatives

## Target binari **y**
Per tal d'elaborar un model lineal que predigui el valor de la variable binaria target *y*, primer hem de decidir quines son les variables (columnes) que utilitzarem en la seva construccio. En altres paraules, trobar quines variables ens aproten informacio i precisio al model predictiu, pero sense sobreparametritzar-lo. 
```{r}
#numeric variables
catdes( dfw[,c("y", vars_con)], 1)

#glm amb les variables continues significatives
gm1<-glm(y~nr.employed+euribor3m+emp.var.rate+pdays+previous+cons.price.idx+cons.conf.idx+campaign, family=binomial, data=dfw); summary(gm1)

Anova(gm1)
vif(gm1) #check colinear variables

#our strategy: remove 2 colinear variables and campagin
gm2<-glm(y~emp.var.rate+pdays+previous+cons.price.idx+cons.conf.idx, family=binomial, data=dfw); summary(gm2)
vif(gm2)

marginalModelPlots(gm2) #some missfit data vs model

```


## Transforming variables
No veiem cap patro en els marginal plots que ens pugui ajudar a l'hora de seleccionar una transformacio de variable en el model.
```{r}
#gm3<-glm(y~emp.var.rate+pdays+poly(previous, 2)+cons.price.idx+cons.conf.idx, family=binomial, data=dfw); summary(gm3)
#Anova(gm3)
#marginalModelPlots(gm3) 

```


## Adding factors
A partir del millor model en aquest punt, comprovem per a cada variable numerica si es millor la seva utilitzacio com a factor o com a numerica. Ens quedem doncs amb un model gm2f, el qual te les variables pdays i f.cons.conf.idx com a factors i la resta com a numeriques.
```{r}
#amb pdays, ojo!!!! pq la continua ha estat majoritariament imputada, per tant en aquest cas, no fem cas del test, agafem la factoritzada!
gm2<-glm(y~emp.var.rate+f.pdays+previous+cons.price.idx+cons.conf.idx, family=binomial, data=dfw)

#f.emp.var.rate or emp.var.rate?
gm2f<-glm(y~f.emp.var.rate+f.pdays+previous+cons.price.idx+cons.conf.idx, family=binomial, data=dfw)
BIC(gm2, gm2f) #f.emp.var.rate dona pitjor (mes baix) BIC, per tant ens quedem amb la variable numerica

gm2f<-glm(y~emp.var.rate+f.pdays+f.previous+cons.price.idx+cons.conf.idx, family=binomial, data=dfw)
BIC(gm2, gm2f) #previous com a numerica

gm2f<-glm(y~emp.var.rate+f.pdays+previous+f.cons.price.idx+cons.conf.idx, family=binomial, data=dfw)
BIC(gm2, gm2f) #cons.price.idx com a numerica

gm2f<-glm(y~emp.var.rate+f.pdays+previous+cons.price.idx+f.cons.conf.idx, family=binomial, data=dfw)
BIC(gm2, gm2f) #f.cons.conf.idx com a factor

```

# Variables discretes explicatives
Ara afegirem les variables discretes explicatives que siguin significatives, ho farem a partir de les que ens indiqui el catdes, sempre sense repetir una variable si ja esta represetnada com a numerica. Mirem les colinearitats i eliminem les variables que en tinguin, per a continuaciO simplifIcar el model amb la comanda step. Veiem com finalment el model gm44 es un model sense colinearitats, on tots els efectes de les variables explicatives son significatius.
```{r}
#discrete variables
catdes( dfw[,c("y", vars_dis)], 1)

#assumim gm2f el millor model en aquest punt i li afegim les significatives (entre month i f.season triem la primera):
gm4<-glm(y~emp.var.rate+f.pdays+previous+cons.price.idx+f.cons.conf.idx+f.nr.employed+poutcome+f.euribor3m+contact+default+f.age+education+month+marital+f.campaign, family=binomial, data=dfw); summary(gm4)

vif(gm4) #valor de colinearitat en la 2a columna (eliminem fins a obtenir tots els valors <3)
gm4<-glm(y~previous+cons.price.idx+f.cons.conf.idx+poutcome+f.euribor3m+contact+default+f.age+education+month+marital+f.campaign, family=binomial, data=dfw); summary(gm4); vif(gm4); Anova(gm4)

gm44<-step(gm4, k=log(nrow(dfw))); 
vif(gm44); 
summary(gm44)


#provem si f.season va millor que la variable month
gm44season<-glm(y~f.cons.conf.idx+poutcome+f.euribor3m+f.season, family=binomial, data=dfw)


#equivalent al test de Fisher pero per al target factor (binari):
anova(gm44, gm44season, test="Chisq") #Pr(>Chi) < 2.2e-1 -> no son equivalents, per tant el model mes gran (amb month que te mes categories) hauria de ser millor

#podriem crear una nova variable a partir de months que sigui months bons i dolents, podria simplificar el model!!

```

## Interactions

En aquest apartat intentarem millorar el nostre model actual a traves de les interaccions. Establirem un model inicial (gmint) que anira acumulant les millores en cas de que l'aportacio de les interaccions sigui positiva per al model. En el primer cas provarem l'interaccio amb month:
```{r}
gmint<-glm(y~f.cons.conf.idx+poutcome+f.euribor3m+month, family=binomial, data=dfw)

gmint1<-glm(y~(f.cons.conf.idx+poutcome+f.euribor3m)*(month), family=binomial, data=dfw);
Anova(gmint1, test="LR");
```

Podem veure que la interacció amb month no implica una aportacio rellevant en el model. Aixi doncs, ens mantenim amb el model inicial. A continuacio provarem amb l'interaccio amb f.euribor3m:
```{r}
gmint2<-glm(y~(f.cons.conf.idx+poutcome+month)*(f.euribor3m), family=binomial, data=dfw);
Anova(gmint2, test="LR");

```

Podem observar com l'interaccio provinents poutcome i month amb f.euribor3m pot ser valuosa per al model. 
```{r}
gmint22<-step(gmint2, k=log(nrow(dfw)));
Anova(gmint22, test="LR");

gmint<-glm(y~f.cons.conf.idx+poutcome+f.euribor3m+month+poutcome:f.euribor3m+month:f.euribor3m, family=binomial, data=dfw)
```
Amb l'step podem observar com les interaccions amb poutcome i month aporten valor rellevant al nostre model. Aixi doncs, guardem el nostre model i seguint treballant amb les demes variables per tal de trobar noves millores.

```{r}
gmint3<-glm(y~(f.cons.conf.idx+f.euribor3m+month+poutcome:f.euribor3m+month:f.euribor3m)*(poutcome), family=binomial, data=dfw);
Anova(gmint3, test="LR");

gmint32<-step(gmint3, k=log(nrow(dfw)));
Anova(gmint32, test="LR"); #la potencial interaccio valuosa finalment no ens aporta valor afegit 

gmint4<-glm(y~(poutcome+f.euribor3m+month+poutcome:f.euribor3m+month:f.euribor3m)*(f.cons.conf.idx), family=binomial, data=dfw);
Anova(gmint4, test="LR");

gmint42<-step(gmint4, k=log(nrow(dfw)));
Anova(gmint42, test="LR"); #f.euribor3m:f.cons.conf.idx valuos

gmint<-glm(y~f.cons.conf.idx+poutcome+f.euribor3m+month+poutcome:f.euribor3m+month:f.euribor3m+f.euribor3m:f.cons.conf.idx, family=binomial, data=dfw)
```

Un cop incorporades les interaccions fem la comparacio amb el model anterior. Veiem que el model sense interaccions es millor, aixi que ens mantindrem treballant amb el model gm44.
```{r}
BIC(gmint, gm44);
```

#Validacio del model
```{r}
Boxplot(rstudent(gm44))
abline(h=c(2,-2), col="red", lwd=2)
out<-which(rstudent(gm44)>=2 | rstudent(gm44)<=-2); length(out)

inf<-Boxplot(cooks.distance(gm44))
llinf<-which(abs(cooks.distance(gm44))>3); length(llinf) #limit correcte?

influencePlot(gm44)

#model final
mfinal<-glm(y~f.cons.conf.idx+poutcome+f.euribor3m+month, family=binomial, data = dfw)
```

#Prediccio
```{r}
pred<-predict(mfinal, type="response", newdata=dft)
predn<-as.numeric(pred)
summary(df$y)

pred.y <- factor(ifelse(predn<0.5, 0, 1), labels=c("pred.y-no", "pred.y-yes"))

table<-table(pred.y, dft$y); table
```
Considerant un threshold de 0,5 (equitatiu per als dos valors possibles de sortida) obtinim uns resultats bastant pobres. Anem a trobar un millor valor a traves de les corves ROC.
```{r}
dadesroc<-prediction(predict(mfinal,type="response"),dfw$y)
par(mfrow=c(1,2))
plot(performance(dadesroc,"err"));
plot(performance(dadesroc,"tpr","fpr"))
abline(0,1,lty=2)
```
En el grafic de la dreta podem veure com la curva dista molt de concidir amb el marge superior esquerra, aixo ens indica una baixa capacitat predictiva del model. Amb el grafic de l'esquerra podem veure que els valor del threshold que tindran una menor "error rate" es trobarien entre 0,5 i 0.6. Anteriorment ja hem testejat la capicitat predictiva per un valor de 0.5 en threshold, ara provem amb 0.6 per veure si podem obtenir certa millora. 
```{r}
pred2<-predict(mfinal, type="response", newdata=dft)
pred2n<-as.numeric(pred2)
summary(df$y)

pred2.y <- factor(ifelse(pred2n<0.6, 0, 1), labels=c("pred2.y-no", "pred2.y-yes"))

table2<-table(pred2.y, dft$y); table
```
Els resultats obtiniguts son igual de pobres en els dos casos, ens quedarem amb aquell threshold que ens ofereixi una taxa d'error menor.
```{r}
err05<-100*sum(diag(table))/sum(table); err05
err06<-100*sum(diag(table2))/sum(table2); err06
```
El threshold de 0.5 ofereix una taxa d'encert llegerament millor. Aixi doncs, ens quedarem amb aquest threshold per a realitzar les prediccions. 



## Target numeric **duration**
Per tal d'elaborar un model lineal que predigui el valor de la variable numerica target *duration*, primer hem de decidir quines son les variables (columnes) que utilitzarem en la seva construccio. En altres paraules, trobar quines variables ens aproten informacio i precisio al model predictiu, pero sense sobreparametritzar-lo. 

## Model inicial amb totes les variables numeriques
Una primera (i dolenta) aproximacio podria ser la d'usar un model lineal inicial que tingui en compte totes les variables numeriques aportades. Veiem com aquestes variables en un model lineal nomes ens expliquen l' 1.3% de la variabilitat de l'output *duration* (Multiple R-squared: 0.01309)! El que vol dir que gairebe un 99% d'questa variabilitat de la duracio queda sense explicar, el que vol dir que aquesta primera aproximacio, a part d'estar sobreparametritzada, no prediu gens be.
```{r}
vars_con
#li treiem la variable target a la llista de variables numeriques explicatives
vars_exp<-c(vars_con[1], vars_con[3:10]); vars_exp

m1<-lm(duration~., data=df[,vars_con]) #es passa nomes el df amb les variables continues perque li hem posat un '.' al model que vol dir que les agafi totes, i ara nomes volem variables explicatives numeriques; si especificiquem les variables numeriques explicatives del model i volem que el calculi per tot el df incloent variables categoriques, "data" el passem com =df.
summary(m1)
```


## Model inicial amb nomes les variables numeriques rellevants
Una altra opcio mes adient seria la d'obtenir un model inicial utilitzant nomes les variables numeriques que son rellevants, i a partir d'aqui mirar si es pot reduir la parametritzacio del model i seguir amb un bon ajust predictiu de la variabilitat del nostre output *duration*. Per a trobar les variables rellevants, podem realitzar tests de Fisher mitjancant la comanda Anova d'R, o be utilitzar la comanda condes vista en anteriors entregues.

### Inferential criteria o Bayesian info criteria
Utilitzem la comanda Anova per a realitzar tests de Fisher i detectar i eliminar variables poc explicatives en els models.

El test Anova ens diu linia a linia si cada variable es significativa a l'hora d'aportar informacio en el model. Cada fila es refereix a un test de models encaixats del model m1 amb el model m1 sense la variable expressada en la fila.Per tant, si el p-valor es <0.05 podem refutar la H0 que deia que els models eren iguals. La podem refutar amb les variables age i indicadors socioeconomics, que vol dir que no ens aporten informacio extra al model. En canvi, per les variables campaign, pdays, previous i emp.var.rate, no podem refutar la H0, el que vol dir que si que ens estan aportant informacio al model i no les podem eliminar. Podriem contemplar tambe quedar-nos amb nr.employed, ja que esta prop de la frontera del p-valor teoric vs la flexibilitat a la practica. El model m2 es el model obtingut amb aquestes variables rellevants.
```{r}
#METODE TESTS FISHER:
#remove non significant variables, per a saber quines son fem tests de Fisher amb la comanda Anova d'R
Anova(m1)

m2<-lm(duration~campaign+pdays+previous+emp.var.rate+nr.employed, data=df)
Anova(m2)
```

Un altre metode pas a pas es el metode Akaike. Va eliminant en models successius les variables que treient-les, obtindriem un AIC mes baix, ja que ens interessa un coeficient d'Akaike que quan no li treiem cap variable es mantingui igual. Un trade-off entre el fitting del model i la sobre parametritzacio. El model m3 *duration ~ campaign + pdays + previous + emp.var.rate + cons.conf.idx + nr.employed* es el model obtingut amb aquest metode.
```{r}
#AKAIKE:
m3<-step(m1)
```

Hi ha un altre metode anomenat Bayesian, el qual es millor per a mostres grans com la nostra, ja que tot i funcionar com l'anterior, solen sortir models mes simplificats. El model m4 *duration ~ campaign + emp.var.rate + nr.employed* es el model obtingut amb aquest metode.
```{r}
#BAYESIAN (BIC):
m4<-step(m1, k=log(nrow(df)))
summary(m4)
```


### Condes per a obtenir les variables numeriques rellevants
Utilitzant la comanda condes vista en anteriors entregues tambe podem trobar les variables que son rellevants pel nostre model. El model que obtenim aixi es el m5, i la comanda Anova ens diu que pdays no esta aportant res de nou (p-value=0.32). La treiem i ens queda el model m6, que correspon a *duration ~ euribor3m + nr.employed + campaign*.
Si apliquem un metode BIC en aquest model obtenim un model m7 amb nomes un sol parametre aportant informacio que es campaign. Aquest model es massa simple i no ens va be per a treballar, aixi que ens quedem amb el model m4 obtingut anterirment tambe pel metode Bayesian.
```{r}
condes(df, 11) #variable target: 11 (duration)

#Agafem com a variables explicatives les $quanti del condes:
m5<-lm(duration~pdays+euribor3m+nr.employed+campaign, data=df); Anova(m5)
m6<-lm(duration~euribor3m+nr.employed+campaign, data=df); Anova(m6) #totes les variables ens aporten informacio nova

#BIC
m7<-step(m6, k=log(nrow(df)))
```

La comanda vif d'R ens diu les variables utilitzades en el model tenen redundancies. Si el seu valor esta per sota de 3 es valid; i si dos valors son iguals vol dir que d'aquelles dues variables ens n'em de quedar nomes una! En el cas del model m4 ens quedarem amb la variable campaign i nr.employed (triada d'entre les dues amb valor similar).
```{r}
vif(m4)
m44<-lm(duration~campaign+nr.employed, data=df); Anova(m44)
```


## Plots del model m4
```{r}
par(mfrow=c(2,2))
plot(m4) #models forca dolents
par(mfrow=c(1,1))
```
###Residual vs fitted
En aquesta grafica podem veure els valors dels residus en l'eix Y i els valors ajustats en l'eix X. El nuvols de punts s'hauria de trobar encaixat dins un marge delimitat per dues linies paral.leles reconeixibles a la vista, fet que no podem veure en el nostre grafic i ens indica la incorrectesa del model. A mes, tambe podem apreciar com els residus no es troben distribuits de manera aleatoria, sino que es concentren en la part central de la grafica de manera molt significativa.

###Normal Q-Q
Aquesta grafica es mostra els residus envers als seus valors esperats en el suposit d'una distribucio normal. Podem refutar que els residus segueixen una distribucio normal donat que es dispersen significativament de la recta de punts. Podem interpretar com els valors situats al marge superior dret podrien tractar-se d'outliers. Tambe podem identificar una corva ascendent, fet que ens indica que ens trobem davant una distribucio amb asimetria a l'esquerra.

###Scale-Location
L'objectiu d'aquesta grafica es veure un nuvol de punts distribuits de manera aleatoria sobre la linea horitzontal, per tal de poder demostra-ne homocedasticitat. Es pot apreciar a claredad que el factor anterior no es compleix i que, de nou, els punts es concentren en la part central de l'eix de les x i, en aquest punt, s'extenen a llarg de l'eix de les y, mentre que en els extrems podem observar menor quantita de punts i lleugerament més centrats sobre la recta en el cas de l'extrem esquerra.

###Residual vs leverage
Aquesta grafica ens ajuda a identificar "influent data" en els nostres residus basant-se en la distancia de Cook. Les observacions influents es troben en el marge superior dret o en el marge inferior dret. En la nostra grafica podem apreciar com la major concentracio de punts es troba al marge esquerre, per tant no podem extreure grans conclusions en relacio al comportament dels outliers en el nostre model.

```{r}
residualPlots(m4)

marginalModelPlots(m4)

influencePlot(m4)
Boxplot(cooks.distance(m4))
```

###ResidualPlots
Aquesta comanda ens mostra els residus contra cada terme del model i els valors ajustats. També calcula una prova de curvatura per cadascuna de les gràfiques afegint un terme quadràtic i provant el quadràtic com a zero. Per als models lineals, es tracta de la prova de Tukey per a la no additivitat en representar els valors ajustats.

En les grafiques que enfronten els residus i una de les variables podem veure com en cap d'elles podem indentificar un patro que ens sugereixi un canvi en el nostre model. Un exemple podria ser un corva que ens indiques que aquella variable milloria el model si s'eleves al cuadrat.

###marginalModelPlots
De la mateixa manera que en la comanda anterior, obtenim un conjunt de grafics que enfronten els residus amb cada terme utilitzat en el model i els valors ajustats. El cas de que la funcio de de les variables, identificada com a Data, i la dels valors predits, identificada com a Model, siguessin similars ens estaria indicats que el model s'ajusta correstament per aquella variable. Podem veure com la funcio Data difereix dels valors predits en cada una de les grafiques. Com hem vist a partir de les diferents grafiques anteriors, ens indica que el model escollit no es l'apropiat. 

###influencePlot
Aquesta comanda crea un grafic de bombolles amb el valor dels residus "studentitzats", on el diametre de les bombolles mante una relació proporcional a la seva distancia de Cook, expresa en forma de boxplot en la seguent comanda. D'aquesta manera i através de la taula que s'ens mostra com a output podem indetificar com les mostres 8993, 9206 i 18712 son les que mes condicionen el model.

Les linies vertical estan dibuixades en 2 i 3 vegades el valor mitja dels "hat values" i les linies verticals es troben als punts 2, 0 i -2 de la escala de residus "studentitzats". 




## Transformacio la variable target numerica
A vegades una transformacio de la variable target numerica pot millorar el model. La comanda Bo-Cox ens mostra com el valor de lambda estimat es proper a 0, vol dir que hem d'elevar a 0 el target, com que aixo no es pot fer i amb les grafiques anteriors no em pogut indetificar cap patro que ens induis a elevar alguna de les variables, la transformacio estadistica del nostre target sera el logaritme, i la farem a partir del model m5 obtingut anteriorment (aixi donarem marge a possibles reduccions del mateix).
```{r}
#Box-Cox
boxcox(m5, data=df)

#TRANSFORMACIO LOGARITMICA Y(m5) -> logY
m8<-lm(log(duration)~pdays+euribor3m+nr.employed+campaign, data=df); Anova(m8)

#BIC
m10<-step(m8, k=log(nrow(df))); vif(m10) #euribor3m i employed mostren molta colinearitat, ens quedem amb euribor3m
m11<-lm(log(duration)~euribor3m+campaign, data=df); vif(m11)
summary(m11)

#POLINOMIC REGRESSION
#com hi ha poques variables provem de transformar-les totes amb regressio polinomica
m20<-lm(log(duration)~poly(euribor3m, 2)+poly(campaign, 2), data=df)
summary(m20); Anova(m20) #veiem com amb ambdos termes quadratics(2) tenen un p-value <0.05. Es millor que el terme lineal(1) en el cas d l'euribor3, podriem fer per tant aquesta transformacio quadratica.

par(mfrow=c(2,2))
plot(m20)
par(mfrow=c(1,1))

```

A traves de la grafica Normal Q-Q, podem observa com el nou model s'ajusta molt mes que l'anterior a una distribucio normal i en podem identificar unes cues amb tendencia inferior respecte a la linia de la normal. 

Per altra banda, també podem observar com en "Residuals vs Leverage" la majoria del punts es concentra a la part esquerra de la grafica, ens indica que no tenim valors influents, cap del valors es troba mes enlla dels marges del leverage (les linies no es dibuixen).

###Comparacio dels dos models (NO FUNCIONA)
```{r}

plot(df, fitted.values(m4), col="black", pch=19, main="Dataset C")
lines(residuals(m4), fitted.values(m4), col="red", lwd=2, lty=2)
lines(df, fitted.values(m20), col="green", lwd=2, lty=2)
```



# Variables discretes explicatives
Mitjancant la comanda condes intentarem trobar variables discretes que estiguin relacionades amb la variable target numerica duration. D'aquesta manera sabrem quines variables discretes podem utilitzar en el model predictiu per a que ens aportin informacio. 
A partir del millor model anterior de variables continues, hem d'obtenir un nou model afegint les variables discretes i factoritzades (no a partir d'una que ja estava al model). En el nostre cas agafem campaign i nr.employed com a variabels continues, i afegim f.cons.conf.idx+f.cons.price.idx+month+f.euribor3m+poutcome com a variables discretes.
```{r}
condes(df[, c("duration", vars_dis)], 1, proba=0.01)

#campaign+nr.employed son continues, del millor model anterior amb vairables continues
m60<-lm(log(duration)~campaign+nr.employed+f.cons.conf.idx+f.cons.price.idx+month+f.euribor3m+poutcome, data=df)
summary(m60)
Anova(m60)
```

Si el condes anterior ens ha donat com a variables factor significatives algunes que ja teniem en el model com a continues, hem de triar o una o altra versio. Si tenim dubtes entre agafar una variable com a continua o factoritzada, hem de fer el seguent:
Veiem com en ambdues variables obtenim que es millor usar la seva versio numerica (no factoritzada).
```{r}
#per campaign, mateix model pero amb f.campaign enlloc de campaign:
maux<-lm(log(duration)~f.campaign+nr.employed+f.cons.conf.idx+f.cons.price.idx+month+f.euribor3m+poutcome, data=df)

#com que m60 i maux no son anidats, no els modem comparar amb un test de Fisher --> BIC
BIC(m60, maux) #choose option with minimum BIC -> better
#      df      BIC
# m60  24 13143.82  --> millor model amb campaign com a numerica
# maux 25 13199.11

maux<-lm(log(duration)~campaign+f.nr.employed+f.cons.conf.idx+f.cons.price.idx+month+f.euribor3m+poutcome, data=df)
BIC(m60, maux)
#      df      BIC
# m60  24 13143.82  --> millor model amb nr.employed com a numerica
# maux 25 13151.61

#si haguessim hagut de fer el mateix amb pdays, ojo!!!! pq la continua ha estat majoritariament imputada, per tant en aquest cas, tot i el test, hauriem d'agafar la factoritzada!
```

Mirem si podem simplificar el model eliminant variables poc significatives mitjancant la comanda step i veiem com ens podem quedar amb les variables numeriques nr.employed i campaign, i la variable factor f.cons.price.idx.
Si ho fem mitjancant la comanda Anova, veiem com ens surt el mateix resultat pero agafant tambe la variable discreta poutcome. Aixi doncs tambe li farem cas i aquest model sera el m62, que explica el 5% (R^2=0.04959) de la variabilitat de l'output del logaritme de *duration*.
```{r}
m61<-step(m60, k=log(nrow(df)))

Anova(m60)
m62<-lm(log(duration)~campaign+nr.employed+f.cons.price.idx+poutcome, data=df); summary(m62)
```


```{r}
summary(df[, c("campaign", "nr.employed", "f.cons.price.idx", "poutcome")])
model.matrix(m62)
```


# Interactions
Partint del model anterior, li afegim interaccions 2 a 2 entre totes les seves variables, simplifiquem i veiem com hi ha dues interaccions significatives: campaign:nr.employed i campaign:f.cons.price.idx. Nomes podem tenir en compte en el nostre model pero, interaccions entre factors o entre factor i variable numerica, aixi que amb el tests d'Anova mirarem manualment quines interaccions valides ens quedem, el que ens porta a un model m73.
```{r}
#interaccio entre 2 variables:
m70<-lm(log(duration)~(campaign+nr.employed+f.cons.price.idx+poutcome)^2, data=df)
summary(m70);coef(m70)
m71<-step(m70, k=log(nrow(df))); Anova(m71) #el criteri Anova(fisher) reafirma el step(BIC) en aquest cas :)!
# log(duration) ~ campaign + nr.employed + f.cons.price.idx + campaign:nr.employed + campaign:f.cons.price.idx
# 
#                             Df Sum of Sq    RSS     AIC
# <none>                                   3907.1 -1130.7
# - campaign:nr.employed       1    13.192 3920.3 -1122.4
# - campaign:f.cons.price.idx  3    30.057 3937.1 -1118.0
anova(m71, m70) #Pr(>F) = 0.03967 *  --> els models no son equivalents


Anova(m70)
#                              Sum Sq   Df  F value    Pr(>F)    
# campaign                      139.1    1 177.5733 < 2.2e-16 ***
# nr.employed                     4.9    1   6.2304  0.012590 *  
# f.cons.price.idx               31.3    3  13.3261 1.162e-08 ***
# poutcome                        8.9    2   5.7067  0.003345 ** 
# campaign:nr.employed            7.7    1   9.8365  0.001721 **  --> entre dos numeriques
# campaign:f.cons.price.idx      25.3    3  10.7841 4.635e-07 *** --> entre numerica i factor --> agafem
# campaign:poutcome               0.2    2   0.1354  0.873389     --> entre numerica i factor
# nr.employed:f.cons.price.idx    5.8    3   2.4861  0.058763 .   --> entre numerica i factor
# nr.employed:poutcome            1.8    2   1.1741  0.309191     --> entre numerica i factor
# f.cons.price.idx:poutcome       7.9    6   1.6823  0.121019     --> entre factors --> agafem aquest per l'entrega

m73<-lm(log(duration)~campaign+nr.employed+f.cons.price.idx+poutcome+campaign:f.cons.price.idx+f.cons.price.idx:poutcome, data=df)
anova(m73, m70) #Pr(>F) = 0.003286 **  --> els models no son equivalents

```

## Interaction between a couple of factors
```{r}
#f.cons.price.idx:poutcome
m80<-lm(log(duration)~f.cons.price.idx+poutcome, data=df); summary(m80)

scatterplot(log(duration)~f.cons.price.idx|poutcome, data=df)

```

## Interaction between factor and covariate
```{r}
#campaign|f.cons.price

#model petit sense interaccions
m85<-lm(log(duration)~campaign+f.cons.price.idx, data=df); summary(m85)
scatterplot(log(duration)~campaign|f.cons.price.idx, data=df) #Suport visual
plot(allEffects(m85)) #effects library

#model gran amb interaccions: 3 parametres-> campaign, f.cons.price.idx, campaign:f.cons.price.idx
m855<-lm(log(duration)~campaign*f.cons.price.idx, data=df); summary(m855) 
#are interactions significant?
anova(m85, m855) #Pr(>F)  5.152e-05 ***  --> H0 rejected --> m855 X*A 
plot(allEffects(m855))



#campaign|poutcome --> segons el test anterior, la interaccio no ha sortit gaire significativa, pero s'interpreta millor visualment
m86<-lm(log(duration)~campaign+poutcome, data=df); summary(m85)
scatterplot(log(duration)~campaign|poutcome, data=df)
plot(allEffects(m86))

m866<-lm(log(duration)~campaign*poutcome, data=df); summary(m866) 
anova(m86, m866) #Pr(>F)  0.1435  --> H0 accepted --> els models son iguals, per tant no cal el model gran amb interaccions 
```

