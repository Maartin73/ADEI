---
output:
  pdf_document: 
    fig_width: 6
    fig_height: 4
  html_document: default
editor_options: 
  chunk_output_type: console
---

# Course Practical Assignment - 3rd Deliverable (juny 2019)
## *Josep Clotet Ginovart*
## *Eric Martin Obispo*

# Bank client data
## Description of input variables:

  1. age (numeric)
  2. job : type of job (categorical: 'admin', 'blue-collar', 'entrepreneur', 'housemaid', 'management', 'retired', 'self-employed', 'services', 'student', 'technician', 'unemployed', 'unknown')
  3. marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)
  4. education (categorical:'basic.4y', 'basic.6y', 'basic.9y', 'high.school', 'illiterate', 'professional.course', 'university.degree', 'unknown')
  5. default: has credit in default? (categorical: 'no','yes','unknown')
  6. housing: has housing loan? (categorical: 'no','yes','unknown')
  7. loan: has personal loan? (categorical: 'no','yes','unknown')# related with the last contact of the current campaign:
  8. contact: contact communication type (categorical:'cellular','telephone')
  9. month: last contact month of year (categorical: 'jan', 'feb', 'mar',..., 'nov', 'dec')
  10. day_of_week: last contact day of the week (categorical:'mon','tue','wed','thu','fri')
  11. duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.
  12. campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)
  13. pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)
  14. previous: number of contacts performed before this campaign and for this client (numeric)
  15. poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')# social and economic context attributes
  16. emp.var.rate: employment variation rate - quarterly indicator (numeric)
  17. cons.price.idx: consumer price index - monthly indicator (numeric)
  18. cons.conf.idx: consumer confidence index - monthly indicator (numeric)
  19. euribor3m: euribor 3 month rate - daily indicator (numeric)
  20. nr.employed: number of employees - quarterly indicator (numeric)
  21. y - has the client subscribed a term deposit? (binary: 'yes','no')

# Loading packages:
```{r, include=FALSE}
# Required Packages: to be increased over the course
requiredPackages <- c("car","knitr","ggplot2","FactoMineR","missMDA","mvoutlier","chemometrics", "factoextra", "MASS", "effects", "ROCR")
missingPackages <- requiredPackages[!(requiredPackages %in% installed.packages()[,"Package"])]

if(length(missingPackages)) install.packages(missingPackages)
lapply(requiredPackages, require, character.only = TRUE)

```

# Load validated data from Deliverable 1:
```{r}
#invisible() prevent hte output in console of the function
#dirwd<-"D:/Users/Usuari/Documents/ADEIpractica"
#dirwd<-"//pax/perfils/1173408.CR/Downloads/deliverable"
dirwd<-"D:/Documents/GitHub/ADEI"
setwd(dirwd)

load( paste0(dirwd, "/bank-additional/Bank5000_validated.RData") )
summary(df)
```


# Linear Model Building - target numeric "*duration*" de la trucada 
Per tal d'elaborar un model lineal que predigui el valor de la variable numerica target *duration*, primer hem de decidir quines son les variables que utilitzarem en la seva construccio. En altres paraules, trobar quines variables ens aporten informacio i precisio al model predictiu, pero sense sobreparametritzar-lo. 

## Variables numeriques explicatives pel target numeric

### Model inicial amb totes les variables numeriques
Una primera (i dolenta) aproximacio podria ser la d'usar un model lineal inicial que tingui en compte totes les variables numeriques aportades. Veiem com aquestes variables en un model lineal nomes ens expliquen l' 1.3% de la variabilitat de l'output *duration* (Multiple R-squared: 0.01309)! El que vol dir que gairebe un 99% d'questa variabilitat de la duracio queda sense explicar; aixi doncs aquesta primera aproximacio, a part d'estar sobreparametritzada, no prediu gens be.
```{r}
vars_con
m1<-lm(duration~., data=df[,vars_con]) #es passa nomes el df amb les variables continues perque 
#li hem posat un '.' al model que vol dir que les agafi totes, i ara nomes volem variables 
#explicatives numeriques; si especificiquem les variables numeriques explicatives del model i volem 
#que el calculi per tot el df incloent variables categoriques, "data" el passem com =df.
summary(m1)
```


### Model inicial amb nomes les variables numeriques rellevants
Una altra opcio mes adient seria la d'obtenir un model inicial utilitzant nomes les variables numeriques que son rellevants, i a partir d'aqui mirar si es pot reduir la parametritzacio del model i seguir amb un bon ajust predictiu de la variabilitat del nostre output *duration*. Per a trobar les variables rellevants, podem realitzar tests de Fisher mitjancant la comanda Anova d'R, o be utilitzar la comanda condes vista en anteriors entregues.

Inferential criteria o Bayesian info criteria
Utilitzem la comanda Anova per a realitzar tests de Fisher i detectar i eliminar variables poc explicatives en els models.
El test Anova ens diu linia a linia si cada variable es significativa a l'hora d'aportar informacio en el model. Cada fila es refereix a un test de models encaixats del model m1 amb el model m1 sense la variable expressada en la fila. Per tant, si el p-valor es <0.05 podem refutar la H0 que deia que els models eren iguals. La podem refutar amb les variables age i indicadors socioeconomics, que vol dir que no ens aporten informacio extra al model. En canvi, per les variables campaign, pdays, previous i emp.var.rate, no podem refutar la H0, el que vol dir que si que ens estan aportant informacio al model i no les podem eliminar. Podriem contemplar tambe quedar-nos amb nr.employed, ja que esta prop de la frontera del p-valor teoric vs la flexibilitat a la practica. El model m2 es el model obtingut amb aquestes variables rellevants.
```{r}
#METODE TESTS FISHER:
#remove non significant variables, per a saber quines son fem tests de Fisher amb la comanda Anova d'R
Anova(m1)

m2<-lm(duration~campaign+pdays+previous+emp.var.rate+nr.employed, data=df)
Anova(m2)
```

Un altre metode pas a pas es el metode Akaike. Va eliminant en models successius les variables que treient-les, obtindriem un AIC mes baix, ja que ens interessa un coeficient d'Akaike que quan no li treiem cap variable es mantingui igual. Un trade-off entre el fitting del model i la sobre parametritzacio. El model m3 *duration ~ campaign + pdays + previous + emp.var.rate + cons.conf.idx + nr.employed* es el model obtingut amb aquest metode.
```{r, results='hide'}
#AKAIKE:
m3<-step(m1)
```

Hi ha un altre metode anomenat Bayesian, el qual es millor per a mostres grans com la nostra, ja que tot i funcionar com l'anterior, solen sortir models mes simplificats. El model m4 *duration ~ campaign + emp.var.rate + nr.employed* es el model obtingut amb aquest metode.
```{r}
#BAYESIAN (BIC):
m4<-step(m1, k=log(nrow(df)))
summary(m4)
```


Condes per a obtenir les variables numeriques rellevants
Utilitzant la comanda condes vista en anteriors entregues tambe podem trobar les variables que son rellevants pel nostre model. El model que obtenim aixi es el m5, i la comanda Anova ens diu que pdays no esta aportant res de nou (p-value=0.38). La treiem i ens queda el model m6, que correspon a *duration ~ euribor3m + nr.employed + campaign*.
Si apliquem un metode BIC en aquest model obtenim un model m7 amb nomes un sol parametre aportant informacio que es campaign. Aquest model es massa simple i no ens va be per a treballar, aixi que ens quedem amb el model m4 obtingut anteriorment tambe pel metode Bayesian.
```{r, results='hide'}
condes(df, 11)
#variable target: 11 (duration)

#Agafem com a variables explicatives les $quanti del condes:
m5<-lm(duration~pdays+euribor3m+nr.employed+campaign, data=df); Anova(m5)
m6<-lm(duration~euribor3m+nr.employed+campaign, data=df); Anova(m6) 
#totes les variables ens aporten informacio nova

#BIC
m7<-step(m6, k=log(nrow(df)))
```

La comanda vif d'R ens diu les variables utilitzades en el model tenen redundancies. Si el seu valor esta per sota de 3 es valid; i si dos valors son iguals vol dir que d'aquelles dues variables ens n'hem de quedar nomes una! En el cas del model m4 ens quedarem amb la variable campaign i nr.employed (triada d'entre les dues amb valor similar), i obtindrem aixi el model m44.
```{r}
vif(m4)
m44<-lm(duration~campaign+nr.employed, data=df)
```


### Plots del model m4
Podem veure en el diagnostic del model que no es gens bo, a continuacio doncs, farem un seguit de transformacions i hi afegirem variables factor explicatives. D'aquesta manera arribarem al nostre model definitiu, el qual diagnosticarem mes en profunditat. 
```{r}
par(mfrow=c(2,2))
plot(m4) #models forca dolents
par(mfrow=c(1,1))

residualPlots(m4)

marginalModelPlots(m4)

influencePlot(m4)
Boxplot(cooks.distance(m4))
```


### Transformacio de la variable target numerica
A vegades una transformacio de la variable target numerica pot millorar el model. La comanda Bo-Cox ens mostra com el valor de lambda estimat es proper a 0, vol dir que hem d'elevar a 0 el target, com que aixo no es pot fer i amb les grafiques anteriors no em pogut indentificar cap patro que ens induis a elevar alguna de les variables, la transformacio estadistica del nostre target sera el logaritme, i la farem a partir del model m4 obtingut anteriorment (aixi donarem marge a possibles reduccions del mateix).
A traves de la grafica Normal Q-Q, podem observar com el nou model s'ajusta molt mes que l'anterior a una distribucio normal i en podem identificar unes cues amb tendencia inferior respecte a la linia de la normal. 
Per altra banda, tambe podem observar com en "Residuals vs Leverage" la majoria del punts es concentra a la part esquerra de la grafica, ens indica que no tenim valors influents, cap del valors es troba mes enlla dels marges del leverage (les linies no es dibuixen).
```{r}
#Box-Cox
boxcox(m4, data=df)

#TRANSFORMACIO LOGARITMICA Y(m4) -> logY
m8<-lm(log(duration)~campaign+emp.var.rate+nr.employed, data=df); Anova(m8)

#BIC
m10<-step(m8, k=log(nrow(df)))
vif(m10) 
#emp.var.rate i nr.employed mostren molta colinearitat, ens quedem amb emp.var.rate 
#per a ser una variable mes entenedora
m11<-lm(log(duration)~emp.var.rate+campaign, data=df)
vif(m11)
summary(m11)
```
```{r, results='hide'}
#POLINOMIC REGRESSION
#com hi ha poques variables provem de transformar-les totes amb regressio polinomica
m20<-lm(log(duration)~poly(euribor3m, 2)+poly(campaign, 2), data=df)
summary(m20)
Anova(m20) 
#veiem com amb ambdos termes quadratics(2) tenen un p-value <0.05. 
#Es millor que el terme lineal(1) en el cas d l'euribor3m, podriem fer per tant aquesta 
#transformacio quadratica.
```
```{r}
par(mfrow=c(2,2))
plot(m20)
par(mfrow=c(1,1))

```


## Variables discretes explicatives pel target numeric
Mitjancant la comanda condes intentarem trobar variables discretes que estiguin relacionades amb la variable target numerica duration. D'aquesta manera sabrem quines variables discretes podem utilitzar en el model predictiu per a que ens aportin informacio. 
A partir del millor model m11 anterior de variables continues, hem d'obtenir un nou model afegint les variables discretes i factoritzades (que no estiguin ja en el model de forma numerica). En el nostre cas agafem campaign i nr.employed com a variables continues, i afegim f.cons.conf.idx+f.cons.price.idx+month+f.euribor3m+poutcome com a variables discretes.
Com que el condes anterior ens ha donat com a variables factor significatives algunes que ja teniem en el model com a continues, hem de triar o una o altra versio. Per a saber si agafar una variable com a continua o factoritzada, hem de fer el seguent i veiem com en ambdues variables obtenim que es millor usar la seva versio numerica (no factoritzada).
```{r, results='hide'}
condes(df[, c("duration", vars_dis)], 1, proba=0.01)
```
```{r}
#a partir del millor model anterior (m11) amb variables continues afegim factors
m60<-lm(log(duration)~campaign+nr.employed+f.cons.conf.idx+f.cons.price.idx+month
        +f.euribor3m+poutcome, data=df)
summary(m60)
Anova(m60)
```
```{r,results='hide'}
#per campaign, mateix model pero amb f.campaign enlloc de campaign:
maux<-lm(log(duration)~f.campaign+nr.employed+f.cons.conf.idx+f.cons.price.idx+month
         +f.euribor3m+poutcome, data=df)

#com que m60 i maux no son anidats, no els modem comparar amb un test de Fisher --> BIC
BIC(m60, maux)
#choose option with minimum BIC -> better
#      df      BIC
# m60  24 13143.82  --> millor model amb campaign com a numerica
# maux 25 13199.11

maux<-lm(log(duration)~campaign+f.nr.employed+f.cons.conf.idx+f.cons.price.idx+month
         +f.euribor3m+poutcome, data=df)
BIC(m60, maux)
#      df      BIC
# m60  24 13143.82  --> millor model amb nr.employed com a numerica
# maux 25 13151.61

#si haguessim hagut de fer el mateix amb pdays, ojo!!!! pq la continua ha estat majoritariament 
#imputada, per tant en aquest cas, tot i el test, hauriem d'agafar la factoritzada!
```

Mirem si podem simplificar el model eliminant variables poc significatives mitjancant la comanda step i veiem com ens podem quedar amb les variables numeriques nr.employed i campaign, i la variable factor f.cons.price.idx.
Si ho fem mitjancant la comanda Anova, veiem com ens surt el mateix resultat pero agafant tambe la variable discreta poutcome. Aixi doncs tambe li farem cas i aquest model sera el m62, que explica el 5% (R^2=0.04959) de la variabilitat.
```{r, results='hide'}
m61<-step(m60, k=log(nrow(df)))

m62<-lm(log(duration)~campaign+nr.employed+f.cons.price.idx+poutcome, data=df); summary(m62)
```


## Interaccions
Partint del model anterior, li afegim interaccions 2 a 2 entre totes les seves variables, simplifiquem i veiem com hi ha dues interaccions significatives: campaign:nr.employed i campaign:f.cons.price.idx. En el nostre model nomes podem tenir en compte interaccions entre dos factors o entre un factor i una variable numerica, aixi que amb el tests d'Anova mirarem manualment quines interaccions ens quedem, el que ens porta a un model m73, que explica el 5.5% (R^2=0.05534) de la variabilitat de l'output del logaritme de *duration*.
```{r, results='hide'}
#interaccio entre 2 variables:
m70<-lm(log(duration)~(campaign+nr.employed+f.cons.price.idx+poutcome)^2, data=df)
summary(m70)
#coef(m70)
invisible(
  m71<-step(m70, k=log(nrow(df)))
)#el criteri Anova(Fisher) reafirma el step(BIC) en aquest cas!
# log(duration) ~ campaign+nr.employed+f.cons.price.idx+campaign:nr.employed+campaign:f.cons.price.idx
# 
#                             Df Sum of Sq    RSS     AIC
# <none>                                   3907.1 -1130.7
# - campaign:nr.employed       1    13.192 3920.3 -1122.4
# - campaign:f.cons.price.idx  3    30.057 3937.1 -1118.0
invisible(
  Anova(m71)
)
anova(m71, m70) #Pr(>F) = 0.03967 *  --> els models no son equivalents

Anova(m70)
#                                  Pr(>F)    
# campaign                       < 2.2e-16 ***
# nr.employed                     0.012590 *  
# f.cons.price.idx               1.162e-08 ***
# poutcome                        0.003345 ** 
# campaign:nr.employed            0.001721 **  --> entre dos numeriques
# campaign:f.cons.price.idx      4.635e-07 *** --> entre numerica i factor --> AGAFEM
# campaign:poutcome               0.873389     --> entre numerica i factor
# nr.employed:f.cons.price.idx    0.058763 .   --> entre numerica i factor
# nr.employed:poutcome            0.309191     --> entre numerica i factor
# f.cons.price.idx:poutcome       0.121019     --> entre factors --> AGAFEM aquest per l'entrega
```
```{r}
m73<-lm(log(duration)~campaign+nr.employed+f.cons.price.idx+
          poutcome+campaign:f.cons.price.idx+f.cons.price.idx:poutcome, data=df)
anova(m73, m70) #p-value 0.003286 **  -> models no son equivalents -> H0 rejected -> m73 es millor
summary(m73)
```

### Interaction between a couple of factors in our model m73
El model escollit m73 considera una interaccio entre dos factors *f.cons.price.idx:poutcome*.
```{r}
scatterplot(log(duration)~f.cons.price.idx, data=df)
scatterplot(log(duration)~poutcome, data=df)
```

### Interaction between a factor and a covariate in our model m73
El model escollit m73 també considera una interaccio entre un factor i una variable numerica *campaign:f.cons.price*.
```{r}
#model petit sense interaccions
m85<-lm(log(duration)~campaign+f.cons.price.idx, data=df)
scatterplot(log(duration)~campaign|f.cons.price.idx, data=df) #Suport visual
plot(allEffects(m85)) #effects library

#model gran amb interaccions: 3 parametres-> campaign, f.cons.price.idx, campaign:f.cons.price.idx
m855<-lm(log(duration)~campaign*f.cons.price.idx, data=df)
#are interactions significant?
anova(m85, m855) #Pr(>F)  5.152e-05 *** --> H0 rejected --> m855 amb la interaccio es millor 
plot(allEffects(m855))


#campaign:poutcome --> segons el test anterior, la interaccio no ha sortit gaire 
#significativa i no s'inclou en el model definitiu, pero s'interpreta millor visualment.
m86<-lm(log(duration)~campaign+poutcome, data=df)
scatterplot(log(duration)~campaign|poutcome, data=df)
plot(allEffects(m86))
m866<-lm(log(duration)~campaign*poutcome, data=df) 
anova(m86, m866) #Pr(>F)  0.1435--> H0 accepted --> els models son iguals, per tant no cal 
#el model gran amb interaccions 
```

## Diagnostics del model definitiu m73

Residual vs Fitted
En aquesta grafica podem veure els valors dels residus en l'eix Y i els valors de duracio en l'eix X. El nuvols de punts s'hauria de trobar encaixat dins un marge delimitat per dues linies paral.leles reconeixibles a la vista, fet que no podem veure en el nostre grafic i ens indica la incorrectesa del model. A mes, tambe podem apreciar com els residus no es troben distribuits de manera aleatoria, sino que es concentren en la part central de la grafica de manera molt significativa. De totes maneres, ha millorat respecte els models inicials.
Normal Q-Q
Aquesta grafica ens mostra els residus envers als seus valors esperats en el suposit d'una distribucio normal. Podem dir que els residus no segueixen ben be una distribucio normal donat que s'allunyen significativament de la recta de punts en els seus extrems.
Scale-Location
L'objectiu d'aquesta grafica es visualitzar la primera grafica pero amb valors de residus estandaritzats per tal de poder demostra-ne homoscedasticitat. Es pot apreciar que no n'hi ha, es a dir, que la variancia dels errors en les diferents observacions no es constant.
Residual vs Leverage
Aquesta grafica ens ajuda a identificar "influent data" en els nostres residus basant-se en la distancia de Cook. En la nostra grafica no s'hi aprecia cap observacio realment influent en el model amb gran distancia de Cook, pero si que s'observen forces observacions amb gran residu. Tot i aixi, no podem extreure grans conclusions mes enlla de dir que el model no es gaire bo.
```{r}
par(mfrow=c(2,2))
plot(m73)
par(mfrow=c(1,1))
```


ResidualPlots
Aquesta comanda ens mostra els residus de Pearson per a cada variable explicativa del model. En cap d'elles podem indentificar un patro que ens suggereixi un canvi o transformacio de la variable en el nostre model.
marginalModelPlots
Mitjançant un plot dels valors de log(duration) de les nostres dades, als qual hi afegeix un smoother blau, podem veure com el nostre model, que esta representat amb un de vermell, no esta predint gaire acuradament (tret del cas nr.employed). Aixo es veu perque no es sobreposen ambdues linies de suavitzacio, aixi doncs, el model obtingut no es gaire apropiat, sobretot en valors de la part esquerra de la grafica.
influencePlot
Aquesta comanda crea un grafic de bombolles amb el valor dels residus "Studentized", on el diametre de les bombolles mante una relacio proporcional a la seva distancia de Cook de l'individu (es veu tambe en el boxplot). Amb l'ajuda de la taula que s'ens mostra podem identificar com les mostres 10038 i 40528 son les mes influents, les que tenen una distancia de Cook mes elevada, es a dir, que treient-les el model canviaria més. Les observacions 39584 i 39699 son les que tenen mes leverage (hat value), es a dir, que cauen mes fora de la majoria de valors predits del model. Tot i que les observacions amb mes leverage poden tenir mes habilitat per a afectar al model, en aquest cas no ho fan, ja que han han caigut en el patro del model i tenen una distancia de Cook baixa, es a dir, no son influents. Per ultim, tambe tenim algunes observacions amb un residu força elevat, com son les 10038, 40528 i 40999.
```{r}
residualPlots(m73)

marginalModelPlots(m73)

influencePlot(m73)
Boxplot(cooks.distance(m73))
```



# Binary Regression Models - target binari d'acceptacio del producte financer "*y*"
Per tal d'elaborar un model lineal que predigui el valor de la variable binaria target *y*, primer hem de decidir quines son les variables (columnes) que utilitzarem en la seva construccio. En altres paraules, trobar quines variables ens aproten informacio i precisio al model predictiu, pero sense sobreparametritzar-lo. 

## Work and test samples division
Dividim la nostra mostra en dues submostres: el 75% de la mostra inicial serà per a treballar amb les dades (dataframe work - *dfw*), i el 25% restant serà per a testejar-les (dataframe test - *dft*).
```{r}
set.seed(69)
sam<-sample(1:nrow(df), 0.75*nrow(df)) #random sample without replacement

dfw<-df[sam,] #work75%
dft<-df[-sam,] #test25%
```


## Variables numeriques explicatives pel target binari
A partir de la informacio del catdes, que ens diu les variables numeriques mes explicatives, generem un model inicial del tipus binomial, i a partir d'aqui el simplificarem per a que no quedi sobreparametritzat (model gm2).
```{r, results='hide'}
#numeric variables
catdes( dfw[,c("y", vars_con)], 1)
```
```{r}
#glm amb les variables continues significatives
gm1<-glm(y~nr.employed+euribor3m+emp.var.rate+pdays+previous+cons.price.idx+
           cons.conf.idx+campaign, family=binomial, data=dfw); summary(gm1)

Anova(gm1)
vif(gm1) #check colinear variables

#our strategy: remove 2 colinear variables and campagin
gm2<-glm(y~emp.var.rate+pdays+previous+cons.price.idx+cons.conf.idx, 
         family=binomial, data=dfw); summary(gm2)
vif(gm2)

marginalModelPlots(gm2) #some missfit data vs model
```

### Transforming variables
No veiem cap patro en els marginal plots que ens pugui ajudar a l'hora de seleccionar una transformacio de variable en el model. Alguns que hem provat no milloraven el model.
```{r}
#gm3<-glm(y~emp.var.rate+pdays+poly(previous, 2)+cons.price.idx+cons.conf.idx, 
#         family=binomial, data=dfw); summary(gm3)
#Anova(gm3)
#marginalModelPlots(gm3) 
```

## Variables discretes explicatives pel target binari
A partir del millor model en aquest punt (gm2), comprovem per a cada variable numerica si es millor la seva utilitzacio com a factor o com a numerica. Ens quedem doncs amb un model gm2f, el qual te les variables pdays i f.cons.conf.idx com a factors i la resta com a numeriques: *y~emp.var.rate+f.pdays+previous+cons.price.idx+cons.conf.idx*.
```{r, results='hide'}
#amb pdays, ojo!!!! pq la continua ha estat majoritariament imputada, per tant en aquest cas, 
#no fem cas del test, agafem la factoritzada!
gm2<-glm(y~emp.var.rate+f.pdays+previous+cons.price.idx+cons.conf.idx, family=binomial, data=dfw)

#f.emp.var.rate or emp.var.rate?
gm2f<-glm(y~f.emp.var.rate+f.pdays+previous+cons.price.idx+cons.conf.idx, family=binomial, data=dfw)
BIC(gm2, gm2f)
#f.emp.var.rate dona pitjor (mes baix) BIC, ens quedem amb la variable numerica

gm2f<-glm(y~emp.var.rate+f.pdays+f.previous+cons.price.idx+cons.conf.idx, family=binomial, data=dfw)

BIC(gm2, gm2f) 
#previous com a numerica

gm2f<-glm(y~emp.var.rate+f.pdays+previous+f.cons.price.idx+cons.conf.idx, family=binomial, data=dfw)
BIC(gm2, gm2f) 
#cons.price.idx com a numerica

gm2f<-glm(y~emp.var.rate+f.pdays+previous+cons.price.idx+f.cons.conf.idx, family=binomial, data=dfw)
BIC(gm2, gm2f)
#f.cons.conf.idx com a factor
```

Ara afegirem les variables discretes explicatives que siguin significatives, ho farem a partir de les que ens indiqui el catdes, sempre sense repetir una variable si ja esta representada com a numerica. Mirem les colinearitats i eliminem les variables que en tinguin, per a continuaciO simplifIcar el model amb la comanda step. Veiem com finalment el model gm44 es un model sense colinearitats, on tots els efectes de les variables explicatives son significatius.
```{r, results='hide'}
#discrete variables
catdes( dfw[,c("y", vars_dis)], 1)
```
```{r}
#assumim gm2f el millor model en aquest punt i li afegim les significatives 
#(entre month i f.season triem la primera):
gm4<-glm(y~emp.var.rate+f.pdays+previous+cons.price.idx+f.cons.conf.idx+f.nr.employed+poutcome
         +f.euribor3m+contact+default+f.age+education+month+marital+f.campaign, family=binomial, data=dfw)
summary(gm4)

vif(gm4) #valor de colinearitat en la 2a columna (eliminem fins a obtenir tots els valors <3)
gm4<-glm(y~previous+cons.price.idx+f.cons.conf.idx+poutcome+f.euribor3m+contact+default+f.age
         +education+month+marital+f.campaign, family=binomial, data=dfw); summary(gm4); vif(gm4)
Anova(gm4)
```
```{r, results='hide'}
gm44<-step(gm4, k=log(nrow(dfw)))
vif(gm44)
summary(gm44)
```
```{r}
#provem si f.season va millor que la variable month
gm44season<-glm(y~f.cons.conf.idx+poutcome+f.euribor3m+f.season, family=binomial, data=dfw)
#equivalent al test de Fisher pero per al target factor (binari):
anova(gm44, gm44season, test="Chisq") #Pr(>Chi) < 2.2e-1 -> no son equivalents, per tant el model
#mes gran (amb month que te mes categories) hauria de ser millor

#podriem crear una nova variable a partir de months que sigui months bons i dolents, 
#podria simplificar el model!!

```


## Interaccions
En aquest apartat intentarem millorar el nostre model actual (gm44) a traves de les interaccions. Establirem un model inicial (gmint) que anira acumulant les millores en el cas de que l'aportacio de les interaccions sigui positiva per al model. En el primer cas provarem la interaccio f.euribor3m amb f.cons.conf.idx, la qual veiem que ens aporta informacio al model.
```{r}
gmint<-glm(y~f.cons.conf.idx+poutcome+f.euribor3m+month, family=binomial, data=dfw)
gmint1<-glm(y~f.cons.conf.idx*f.euribor3m+poutcome+month, family=binomial, data=dfw)

Anova(gmint1); anova(gmint, gmint1, test="Chisq") #H0 rej -> models no equivalents
```

A continuacio, tot i que segons tests Anova anteriors cap variable numerica ens aportava informacio significativa, provarem la interaccion entre una variable factor i una numerica, tal i com se'ns diu a la practica. Sera el cas de la interaccio entre cons.price.idx i f.euribor3m, la qual l'afegirem al model gmint1. Veiem doncs com si que aquesta variable numerica en forma d'interaccio ens aporta infromacio significativa i ens quedem amb el model gmint2.
Si mitjancant la comanda step simplifiquem el model, obtenim el model gmint3, que trobem no ser equivalent al model gmint2, pel qual no acabarem de fer-li cas a la comanda step i ens quedarem amb el model anterior gmint2.
```{r}
gmint2<-glm(y~cons.price.idx:f.euribor3m+poutcome+month+f.cons.conf.idx*f.euribor3m, 
            family=binomial, data=dfw)
Anova(gmint2); anova(gmint1, gmint2, test="Chisq") #H0 rej -> models no equivalents

gmint3<-step(gmint2, k=log(nrow(dfw)))

anova(gmint2, gmint3, test="Chisq")
#H0 rej -> models no equivalents
```

### Interaction between a couple of factors in our model mgint2
El model escollit mgint2 considera una interaccio entre dos factors *f.cons.conf.idx:f.euribor3m*.
```{r}
table(dfw$f.euribor3m, dfw$f.cons.conf.idx)
```

### Interaction between a factor and a covariate in our model mgint2
El model escollit mgint2 també considera una interaccio entre un factor i una variable numerica *cons.price.idx:f.euribor3m*.
```{r}
#model sense interaccions
plot(allEffects(gmint))
```

## Diagnostics del model definitiu gmint2
En els 5 primers grafics de les dues primeres figures que hi ha a continuacio es poden veure els residus de les prediccions del model per a cada variable explicativa. El 6e grafic mostra un test de curvatura.
En les seguents figures i taula veiem les distancies de Cook i els valors barret per a cadascuna de les observacions. Les observacions 24043 i 24031 son observacions molt influents en el model.
```{r}
residualPlots(gmint2, layout=c(1, 3))
influenceIndexPlot(gmint2, vars=c("Cook", "hat")); influencePlot(gmint2)
```


## Prediccions i matriu de confusio de l'acceptacio del producte financer *y*
Primer utilitzarem el model obtingut per a predir la resposta *y* de les dades de treball *dfw*, que son les mateixes amb les quals s'ha cosntruit el model. Despres farem el mateix pero amb les dades de test *dft*, les quals no s'han usat per a al construccio del model. Si obtenim resultats similars en ambdos tests voldra dir que el nostre model esta correctament parametritzat i no ens hem adaptat a les dades de treball a l'hora de construir-lo.
Veiem com per ambdos jocs de dades obtenim els mateixos resultats, amb una precisio del 90% d'encert a l'hora de determinar l'acceptacio o no del producte financer. Les prediccions correctes d'acceptacio del producte financer o *sensibility* son del 60-70%, mentre que les prediccions correctes de rebuig del producte financer son del 90%.
```{r}
#work data
predw<-predict(gmint2, type="response")
predictionw<-prediction(predw, dfw$y)
predw.y <- factor( ifelse(as.numeric(predw)<0.5, 0, 1), labels=c("predw.y-no", "predw.y-yes") )
tablew<-addmargins( table(predw.y, dfw$y) ); tablew

#test data
predt<-predict(gmint2, type="response", newdata=dft)
predictiont<-prediction(predt, dft$y)
predt.y <- factor( ifelse(as.numeric(predt)<0.5, 0, 1), labels=c("predt.y-no", "predt.y-yes") )
tablet<-addmargins( table(predt.y, dft$y) ); tablet

#confussion matrix values
predicions_correctes_w<-sum(diag(tablew[1:2, 1:2]))/sum(tablew[1:2, 1:2])*100; predicions_correctes_w
predicions_correctes_t<-sum(diag(tablet[1:2, 1:2]))/sum(tablet[1:2, 1:2])*100; predicions_correctes_t

predicions_incorrectes_w<-(100-predicions_correctes_w); predicions_incorrectes_w
predicions_incorrectes_t<-(100-predicions_correctes_t); predicions_incorrectes_t

sensibility_w<-tablew[2,2]/sum(tablew[2, 1:2])*100; sensibility_w
sensibility_t<-tablet[2,2]/sum(tablet[2, 1:2])*100; sensibility_t

specificity_w<-tablew[1,1]/sum(tablew[1, 1:2])*100; specificity_w
specificity_t<-tablet[1,1]/sum(tablet[1, 1:2])*100; specificity_t
```

El llindar seleccionat anteriorment per a decidir si una probabilitat es una acceptacio o un rebuig del producte ha estat l'standard de 0.5; a continuacio tambe es buscara si es poden millorar els resultats considerant un altre valor threshold, el qual valorarem a partir de les curves ROC. En el primer grafic veiem com el llindar actual ens garantitza el maxim % d'encert global del model; en el segon grafic pero, veiem tambe com la sensibilitat del model te encara marge de millora, a canvi d'incrementar els falsos positius, es a dir, predir una acceptacio del producte financer i que finalment aquest sigui rebutjat.
```{r}
dadesroc<-prediction(predict(gmint2, type="response"), dfw$y)
plot(performance(dadesroc,"err"));
plot(performance(dadesroc,"tpr","fpr"))
abline(0,1,lty=2)
```

Si canviem el valor llindar *cut off* a 0.7, el que vol dir que serem "mes pesimistes" a l'hora de dir que el client acceptara el producte financer a partir de la probabilitat donada pel model, obtenim uns millors resultats de sensibilitat (per sobre el 70% en ambdues mostres), mentres que la resta de valors segueixen similars. Tot i aixo, aquest valor es podria ajustar segons l'aplicacio fisica real del model predictiu. Si ens interessa estar molt segurs que si predim un outcome positiu aixi sigui, hauriem de pujar el llindar, fet que comportaria que ens estiguessim predint algun valor positiu com a negatiu. Si el que destijem es el contrari, i simplement volem descartar nomes casos que l'outcome seria negatiu amb molta seguretat, hauriem de baixar el llindar.
```{r}
#work data
predw<-predict(gmint2, type="response")
predictionw<-prediction(predw, dfw$y)
predw.y <- factor( ifelse(as.numeric(predw)<0.7, 0, 1), labels=c("predw.y-no", "predw.y-yes") )
tablew<-addmargins( table(predw.y, dfw$y) ); tablew

#test data
predt<-predict(gmint2, type="response", newdata=dft)
predictiont<-prediction(predt, dft$y)
predt.y <- factor( ifelse(as.numeric(predt)<0.7, 0, 1), labels=c("predt.y-no", "predt.y-yes") )
tablet<-addmargins( table(predt.y, dft$y) ); tablet

#confussion matrix values
predicions_correctes_w<-sum(diag(tablew[1:2, 1:2]))/sum(tablew[1:2, 1:2])*100; predicions_correctes_w
predicions_correctes_t<-sum(diag(tablet[1:2, 1:2]))/sum(tablet[1:2, 1:2])*100; predicions_correctes_t

predicions_incorrectes_w<-(100-predicions_correctes_w); predicions_incorrectes_w
predicions_incorrectes_t<-(100-predicions_correctes_t); predicions_incorrectes_t

sensibility_w<-tablew[2,2]/sum(tablew[2, 1:2])*100; sensibility_w
sensibility_t<-tablet[2,2]/sum(tablet[2, 1:2])*100; sensibility_t

specificity_w<-tablew[1,1]/sum(tablew[1, 1:2])*100; specificity_w
specificity_t<-tablet[1,1]/sum(tablet[1, 1:2])*100; specificity_t
```

