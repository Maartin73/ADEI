---
output:
  pdf_document: 
    fig_width: 6
    fig_height: 4
  html_document: default
editor_options: 
  chunk_output_type: console
---

# Course Practical Assignment - 2nd Deliverable (21 d'abril del 2019)
## *Josep Clotet Ginovart*
## *Eric Martin Obispo*

# Bank client data
## Description of input variables:

  1. age (numeric)
  2. job : type of job (categorical: 'admin', 'blue-collar', 'entrepreneur', 'housemaid', 'management', 'retired', 'self-employed', 'services', 'student', 'technician', 'unemployed', 'unknown')
  3. marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)
  4. education (categorical:'basic.4y', 'basic.6y', 'basic.9y', 'high.school', 'illiterate', 'professional.course', 'university.degree', 'unknown')
  5. default: has credit in default? (categorical: 'no','yes','unknown')
  6. housing: has housing loan? (categorical: 'no','yes','unknown')
  7. loan: has personal loan? (categorical: 'no','yes','unknown')# related with the last contact of the current campaign:
  8. contact: contact communication type (categorical:'cellular','telephone')
  9. month: last contact month of year (categorical: 'jan', 'feb', 'mar',..., 'nov', 'dec')
  10. day_of_week: last contact day of the week (categorical:'mon','tue','wed','thu','fri')
  11. duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.
  12. campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)
  13. pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)
  14. previous: number of contacts performed before this campaign and for this client (numeric)
  15. poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')# social and economic context attributes
  16. emp.var.rate: employment variation rate - quarterly indicator (numeric)
  17. cons.price.idx: consumer price index - monthly indicator (numeric)
  18. cons.conf.idx: consumer confidence index - monthly indicator (numeric)
  19. euribor3m: euribor 3 month rate - daily indicator (numeric)
  20. nr.employed: number of employees - quarterly indicator (numeric)
  21. y - has the client subscribed a term deposit? (binary: 'yes','no')

# Loading packages:
```{r, include=FALSE}
# Required Packages: to be increased over the course
requiredPackages <- c("car","knitr","ggplot2","FactoMineR","missMDA","mvoutlier","chemometrics", "factoextra")
missingPackages <- requiredPackages[!(requiredPackages %in% installed.packages()[,"Package"])]

if(length(missingPackages)) install.packages(missingPackages)
lapply(requiredPackages, require, character.only = TRUE)

```

# Load data from Deliverable 1:
```{r}
#dirwd<-"D:/Users/Usuari/Documents/ADEIpractica"
#dirwd<-"//pax/perfils/1173408.CR/Downloads"
dirwd<-"D:/Documents/GitHub/ADEI"
setwd(dirwd)

load( paste0(dirwd, "/bank-additional/Bank5000_validated.RData") )
summary(df)
```



# CORRESPONDENCE ANALYSIS (CA)
Realitzarem un analisi amb taules de correspondencia i mapes de factors entre la variable numerica target duracio discretitzada en 4 nivells (corregit de l'entrega 1) i diversos factors que hem trobat que tenen una correspondencia significativa.

Primer veiem com la duracio de la trucada no te cap relacio amb el job de l'individu, ja que no podem rebutjar la hipotesi *H0: f.duration no te cap relacio amb la variable job* amb el valor p obtingut en el Chi Square test. 
Com mes aprop surten al grafic les categories d'ambdues variables analitzades, mes relacionades estan. En aquesta comparacio, com s'acaba de comentar, no es pot extreure res significatiu, mes enlla que potser les categories job-unemployed i job-self-employed van mes per lliure.
```{r}
# H0: f.duration no te cap relacio amb variable job
chisq.test( table( df$job, df$f.duration) )
# CA - f.duration vs variable job
res.ca<-CA( table( df$job, df$f.duration ) )
lines(res.ca$row$coord[,1], res.ca$row$coord[,2], col="darkblue")
lines(res.ca$col$coord[,1], res.ca$col$coord[,2], col="darkred")
```

Ara testejarem la mateixa hipotesi i mostrarem el mateix mapa de factors pero amb altres categories factor que si que obtindrem que tenen una relacio significativa. El primer cas es l'epoca de l'any **f.season** en la qual es realitza la trucada (p valor = 2.506e-07).
Comparant el profile de la taula de contingencia de proporcions per fila amb el profile marginal de la duracio veiem com hi ha un 28,5% de trucades amb duracions molt curtes a l'estiu respecte un 25% de trucades amb duracions curtes en tot l'any. D'altra banda, hi ha per sobre d'un 27% de trucades amb duracions llargues a la primavera, respecte un 25% de trucades en la mateixa duracio en tot l'any.
Si comparem el profile de la taula de contingencia de proporcions per columna amb el profile marginal de la f.season veiem com el 42.5% de trucades es realitzen a la primavera, i en canvi mes d'un 46% de trucades corresponen a la primavera i a duracions llargues. A mes, el 43.7% de trucades es realitzen a l'estiu, i nomes prop d'un 40% de trucades corresponen a l'estiu i a duracions llargues.
Aquesta mateixa informacio es pot veure representada en un mapa de factors de dues dimensions. Agafant nomes la primera dimensio ja seria suficient per a representar un 98.9% de la variancia del conjunt de les dades (Kaiser: take as many dimensions as eigenvalue > mean of eigenvalues).
```{r}
chisq.test( table( df$f.season, df$f.duration) )

#Row/Column profile
prop.table( table(df$f.season, df$f.duration), 1 ) #1->per files
#Marginal Row/Column profile
prop.table( table(df$f.duration)) #1->per files

prop.table( table(df$f.season, df$f.duration), 2 ) #2->per columnes
prop.table( table(df$f.season)) #2->per columnes


res.ca<-CA( table( df$f.season, df$f.duration) )
attributes(res.ca); res.ca$eig #valors eig no normalitzats!
mean(res.ca$eig[,1]) #Kaiser: take as many dimensions as eigenvalue > mean of eigenvalues
#En una taula de correspondencies simples podem tenir maxim tantes 
#dimensions com categories d'una variable menys 1! 
#f.season te 3 categories -> -1 -> 2 dimensions!!

#La inercia total ens indica com de relacionades estan les dues variables, 
#com mes proxim el valor a 0, menys relacionades estan!
sum(res.ca$eig[,1])

#Coordenades:
#res.ca$row #files son la f.season!
#res.ca$col #columnes son la duration!

```

El segon cas en el qual obtenim una relacio significativa (p valor = 1.203e-07) es el valor de l'euribor **f.euribor3m**, el qual es un indicador trimestral.
Comparant el profile de la taula de contingencia de proporcions per fila amb el profile marginal de la duracio veiem com hi ha un 30.8% de trucades amb duracions molt curtes quan l'euribor te un valor alt, respecte un 25% de trucades amb duracions sense tenir en compte la fluctuacio de l'indicador. De la mateixa manera, quan el valor de l'euribor es baix, hi ha major % de trucades que acaben amb duracions relativament altes.
Si comparem el profile de la taula de contingencia de proporcions per columna amb el profile marginal de f.euribor3m veiem com el 22.8% de trucades es realitzen amb un euribor molt alt, i en canvi un 28.0% de trucades corresponen a un euribor alt i a duracions molt curtes.
A mes, mirant el mapa de factors podem veure aquesta mateixa informacio de manera grafica. Si ens centrem en la 1a dimensio del grafic (que representa un 89% de la variancia del conjunt de les dades), podem observar com hi ha una tendencia similar en ambdues variables (tot i que les duracions extremadament llargues trenquen una molt bona correlacio del 1r eix). Tambe veiem com les categories f.euribor3m-(4.96,5] i f.duration-[5,101] estan molt relacionades ja que es troben molt proximes en el mapa de factors; aixi com tambe les categories f.euribor3m-[0.635,1.33] i f.duration-(177,316].
(Kaiser: take as many dimensions as eigenvalue > mean of eigenvalues, el que equival a agafar 1 sola dimensio).
```{r}
chisq.test( table( df$f.euribor3m, df$f.duration) )

#Row/Column profile
prop.table( table(df$f.euribor3m, df$f.duration), 1 ) #1->per files
#Marginal Row/Column profile
prop.table( table(df$f.duration)) #1->per files

prop.table( table(df$f.euribor3m, df$f.duration), 2 ) #2->per columnes
prop.table( table(df$f.euribor3m)) #2->per columnes


res.ca<-CA( table( df$f.euribor3m, df$f.duration) )
lines(res.ca$row$coord[,1], res.ca$row$coord[,2], col="darkblue")
lines(res.ca$col$coord[,1], res.ca$col$coord[,2], col="darkred")

attributes(res.ca); res.ca$eig #valors eig no normalitzats!
mean(res.ca$eig[,1]) #Kaiser: take as many dimensions as eigenvalue > mean of eigenvalues
#En una taula de correspondencies simples podem tenir maxim tantes 
#dimensions com categories d'una variable menys 1! 
#f.euribor3m te 4 categories -> -1 -> 3 dimensions!!

#La inercia total ens indica com de relacionades estan les dues variables, 
#com mes proxim el valor a 0, menys relacionades estan!
sum(res.ca$eig[,1])

#A vegades va be eliminar algunes categories amb pocs individus d'una variable 
#per a poder veure millor les possibles relacions!
```



# PRINCIPAL COMPONENT ANALYSIS (PCA)

Primerament realitzem un PCA sobre les variables continues de la nostra mostra de dades, on la variables "duration" ha de ser suplementaria, ja que es tracta de la variable target!

## Eigenvalues and dominant axes

El summary ens permet veure els 9 diferents eigenvalues obtinguts amb aquest PCA, amb les seves dades corresponents de percentatges de variancia del conjunt de les dades que respresenten. Segons el criteri de Kaiser, que diu que s'han de descartar les dimensions amb valors eig normalitzats per sota d'1, hauriem d'agafar les 3 primeres dimensions per a una bona representacio del conjunt de dades. 
Essent flexibles amb el criteri de Kaiser, podriem agafar tambe la quarta dimensio, la qual te una variancia del 0.9656, amb un valor molt proxim a 1. La incorporacio d'aquesta nova dimensio ens donaria una variancia acumulada del 81%, obtenint d'aquesta manera una variancia acumulada per sobre el 80%.
Per ultim, si ens basem en la regla del colze (llegurament subjectiva), i l'apliquem sobre el grafic dels eigenvalues i %variancies obtingut amb les llibreries *ggplot*, hauriem d'agafar les 3 primeres dimensions.
```{r}
vars_con<-names(df)[c(1, 11:14, 16:20)]; vars_con #variables continues
vars_dis<-names(df)[c(2:10, 15, 21, 25, 27:36)] #variables discretes

# PCA:
res.pca<-PCA( df[, vars_con], quanti.sup=2, graph=FALSE) #"duration" com a suplementaria
#nb.dec: number of decimal printed
#ncp: number of dimensions printed
summary(res.pca, nb.dec=2, ncp=5, nbind=0)
#GGPLOT: Use modern ggplot facilities per la regla de l'ultim colze:
#at some point the marginal gain will drop, giving an angle in the graph
fviz_eig(res.pca, addlabels=TRUE)
```

## Individuals point of view
Pintem primer el mapa de factors dels individus de les dues primeres dimensions (70% de la variancia del conjunt de dades) i etiquetem amb el numero d'individu els 15 mes contributius.
A continuacio mostrem per a cadascun dels dos primers eixos, les coordenades i el registre complet d'aquests 3 individus mes contributius.
Es fa exactament el mateix amb els individus mes ben representats (cos2) en les dues primeres dimensions.
```{r}
#nomes pinta les etiquetes dels 15 individus mes contributius!
plot(res.pca, choix="ind", cex=0.75, col.ind="black", select="contrib 15", title="Factor map - 15 individus mes contributius")
#2 individus mes contributius al 1r eix:
contrib<-sort(res.pca$ind$contrib[,1], decreasing=TRUE)[1:2]; contrib
df[c(names(contrib)), ]
#2 individus mes contributius al 2n eix:
contrib<-sort(res.pca$ind$contrib[,2], decreasing=TRUE)[1:2]; contrib
df[c(names(contrib)), ]


#nomes pinta les etiquetes dels 15 individus mes ben representats!
plot(res.pca, choix="ind", cex=0.75, col.ind="black", select="cos2 15", title="Factor map - 15 individus mes ben representats")
#2 individus mes ben representats al 1r eix:
repr<-sort(res.pca$ind$cos2[,1], decreasing=TRUE)[1:2]; repr
#df[c(names(repr)), ]
#2 individus mes ben representats al 2n eix:
repr<-sort(res.pca$ind$cos2[,2], decreasing=TRUE)[1:2]; repr
#df[c(names(repr)), ]

```

## Interpretation of the PCA
En el mapa de factors de les variables (2D, primeres dues dimensions) es pot observar en blau la variable "duration" com a suplementaria, la qual surt quasi centrada, el que vol dir que les variables vars_con utilitzades en el PCA no ens ajuden a dir res o predir el valors de la variable target. La variable previous (numero de contactes en campanyes antigues) esta relacionada inversament amb pdays (dies que feia que no es trucava el client per altres campanyes), ja que que com es pot veure en el grafic, ambdues fletxes apunten oposadament. Sembla ser tambe que tots els indicadors socioeconomics (a excepcio una mica de cons.conf.idx) apunten en la mateixa direccio, el que vol dir que estan relacionats entre ells i contribueixen d'una manera similar als eixos.
Es pot veure el % de contribucio de les variables a les tres primeres dimensions mitjancant una eina de la llibreria *ggplot*, on es veu com basicament els indicadors socioeconomics i les variables "previous", "campaign" i "age" son les variables numeriques que mes han contribuit.
El summary ens permet veure tambe de forma numerica la contribucio (ctr) de cadascuna de les variables en els 4 primers eixos, aixi com la qualitat de la representacio (cos2) de les mateixes en cadascun dels eixos. Si be s'acaben de descriure les variables mes contributives, les que estan millor representades (cos2 mes proxim a 1) en el primer eix son euribor3m, emp.var.rate i nr.employed; i en el segon eix son pdays, previous i cons.conf.idx.
Un l'ultim mapa de factors de variables observem els eixos de les dimensions 3 i 4, les quals representen aproximadament un 11% de la variancia de les dades cadascuna.
```{r}
# PCA:
plot.PCA(res.pca, choix = c("var") ) #variables factor map

#GGPLOT contribution of variables
#fviz_pca_var(res.pca)
fviz_contrib(res.pca, choice="var", axes=1:3)+theme_bw()

summary(res.pca, nb.dec=2, ncp=2, nbind=0)

#veure eixos 3 i 4:
res.pca<-PCA(df[, vars_con], quanti.sup=2, axes=3:4)
```

Com que es dificil extreure conclusions a partir nomes de les variables numeriques, en el grafics seguents es pot observar el posicionament de les dues variables suplementaries "f.duration" i "f.euribor3m" en el mapa de factors dels individus. 
En el cas de f.duration, si es mira al mapa de factors ampliat on nomes es representa aquesta variable, sembla ser que te una tendencia a creixer cap al 2n i 3r quadrant composat per les dues primeres dimensions.
En el cas de f.euribor3m, de la mateixa manera, tambe es pot trobar un progressio de les dades al llarg del primer eix, ja que el valor de l'euribor3m augmenta amb el valor de la primera dimensio de les dades.
```{r}
par(mfrow=c(1,1))

#ara afegim dues variables suplementaries!
res.pca<-PCA( df[, c("f.duration", vars_con) ], quanti.sup=3, quali.sup=1, graph = FALSE ) 
plot.PCA(res.pca, choix = c("ind") )
#Unir punts de variables suplementaries en el factor map per a una bona representacio:
plot.PCA(res.pca, choix="ind", invisible="ind")
lines(res.pca$quali.sup$coord[1:2, 1:2], col="blue", lwd="2")
lines(res.pca$quali.sup$coord[2:3, 1:2], col="blue", lwd="2")
lines(res.pca$quali.sup$coord[3:4, 1:2], col="blue", lwd="2")

res.pca<-PCA( df[, c("f.euribor3m", vars_con) ], quanti.sup=3, quali.sup=1, graph = FALSE ) 
plot.PCA(res.pca, choix = c("ind") )
plot.PCA(res.pca, choix="ind", invisible="ind")
lines(res.pca$quali.sup$coord[1:2, 1:2], col="blue", lwd="2")
lines(res.pca$quali.sup$coord[2:3, 1:2], col="blue", lwd="2")
lines(res.pca$quali.sup$coord[3:4, 1:2], col="blue", lwd="2")
```

```{r, include=FALSE}
#valors v.test >1,96 ens indiquen que la categoria ens aporta alguna cosa!
#   --> son les que ens podriem quedar en un subconjunt i que fos l'utlitzat a l'hora de representar graficament i triar els eixos (pels deliverables no cal aixi!).
```



# K-Means Classification (Partitioning - Supervised learning)

K-means es un algoritme de clustering que te com a objectiu agrupar les observacions en un determinat nombre de grups o clusters els quals comparteixin caracteristiques similars. Dit d'altra manera, agrupa els individus de manera que els que estan dins un mateix cluster tinguin unes distancies euclidianes entre ells mes petties que respecte els individus d'altres clusters. Cal tenir en compte que com que el parametre passat a la crida *kmeans* es el numero de clusters que s'han d'obtenir (i no el conjunt inicial de centres), es seleccionen aleatoriament un conjunt inicial de *k* centres de cluster. Aixo vol dir que aquesta seleccio aleatoria pot tenir gran influencia en el resultat final, el qual sera diferent en cada execucio de l'alogritme. Per tal de reduir soroll de les dades innecessari, treballarem nomes amb les 4 primeres dimensions obtingudes del PCA. 

L'objecte retornat per la crida *kmeans* ens permet consultar diferents atributs. L'atribut withinss correspon a la suma del quadrat de les distancies inter-cluster, es a dir, hi ha un valor per a cada cluster. L'atribut betweenss es un sol valor mig que correspon a la suma del quadrat de les distancies inter-cluster. A partir d'aquest valor mig i el total de les distancies totss podem obtenir el nivell de representacio que obtenim nomes amb els centres de gravetat dels clusters sobre el conjunt de les dades.
```{r}
#only 4 significant axes in order to avoid unnecessary noise
dclu<-res.pca$ind$coord[,1:4]

#fixed number of clusters (a random set of rows are chosen as the initial centers)
kcla<-kmeans(dclu, 4)
summary(kcla) 

table(kcla$cluster)

attributes(kcla)

#INTRA-CLUSTER DISTANCES
kcla$withinss
#$withinss: is the within cluster sum of squares. 
#So it results in a vector with a number for each cluster.

#INTER-CLUSTER DISTANCES
kcla$betweenss
#$betweenss: is the between clusters sum of squares. 
#In fact it is the mean of distances between cluster centers.

# Some equalities may help to understand:
#     $tot.withinss = sum($withinss)
#     $totss = $tot.withinss + $betweenss
kcla$tot.withinss
kcla$totss 

kcla$betweenss/kcla$totss
#nomes amb els centres de gravetat estariem obtenint una representacio de les dades del X%
```

Si executem k-means per a diferents valors k podem observar com evolucionen les distancies intra-clusters o el % de representacio obtingut en cada cas. L'execucio d'unes quantes vegades del seguent chunk de codi ens ha ajudat en la seleccio del nombre de clusters, ja que per la regla de l'ultim colze agafem una k=4.
```{r}
wss <- sum(kmeans(dclu,1)$withinss) #k=1
for (i in 2:15) wss[i] <- sum(kmeans(dclu,i)$withinss) #k=2to15

plot(1:15, wss, type="b", xlab="Number of Clusters", ylab="Intra-cluster distances")


km<-kmeans(dclu,1)
repr <- km$betweenss/km$totss #k=1
for (i in 2:15){
  km<-kmeans(dclu,i)
  repr[i] <- km$betweenss/km$totss
}

plot(1:15, repr, type="b", xlab="Number of Clusters", ylab="% de representacio amb els centres de gravetat")

```

## Descripcio dels clusters
Per a fer Eric!
```{r}
kclusters<-as.data.frame(kcla$cluster)
colnames(kclusters) = c("kcluster")
dades_cl<-merge(df[,vars_con], kclusters, by=0) #merge by row.names
dades_cl<-dades_cl[,-1] #eliminem columna row.names (correspon als num de fila anteriors)

dades_cl$kcluster<-as.factor(dades_cl$kcluster)
catdes(dades_cl, 11) #catdes per kcluster
```



# Hierarchical Clustering (Unsupervised learning)

Aquest punt compren la realitzacio d'una clusteritzacio aglomerativa jerarquitzada dels individus. HCPC de la llibreria FactoMineR utilitza les distancies de entre clusters diferents, per tal de minimitzar la inercia inter-cluster.

La primera de les comandes HCPC esta comentada ja que requereix l'interacio de l'usuari per a triar per on tallar l'arbre de clusters que es mostra a l'usuari. Despres d'estar interactuant amb diferents opcions de numero de clusters, s'ha decidit finalment agafar nb.clust = 7, tal i com es pot veure a continuacio. Es mostren els grafics corresponents a l'arbre el qual s'ha tallat a l'altura de 7 clusters, aixi com el mapa de factors de les dues primeres dimensions del PCA.
```{r}
#PCA calculat amb 4 significant axes:
vars_con<-names(df)[c(1, 12:14, 16:20)]; vars_con
res.pca<-PCA( df[, c("duration", "y", "loan", "month", "job", "poutcome", "education", "housing", vars_con) ], quanti.sup=1, quali.sup=2:8, ncp=4, graph=FALSE )

#res.hcpc<-HCPC(res.pca, order=TRUE)

res.hcpc<-HCPC(res.pca, nb.clust=7, order=TRUE, graph=FALSE); res.hcpc
attributes(res.hcpc)

plot.HCPC(res.hcpc, choice="tree")

plot.HCPC(res.hcpc, choice="map")
fviz_cluster(res.hcpc)
```

El guanys (d'1 a 2 clusters, de 2 a 3, de 3 a 4, etc.) d'inercia es poden observar en negre a la figura inferior, on tambe es pot veure la relacio entre altres nivells de tall i els seus guanys. Els valors *within* ens mostren la inercia dins de cada cluster, que si fos un sol cluster (1) seria la total del conjunt de dades, la qual equival a la suma de tots els guanys d'inercies *inert.gain*. Amb la seleccio de 6 clusters que hem agafat estariem obtenint una representacio de les dades del 80.4%, la qual es molt bona! Finalment, tambe podem veure la distribucio en nombre d'individus en els diferents clusters.
```{r}
plot.HCPC(res.hcpc, choice="bar")

res.hcpc$call$t$inert.gain[1:6]
sum(res.hcpc$call$t$inert.gain)

res.hcpc$call$t$within[1:7]

#X clusters corresponen al %? d'inercia
sum(res.hcpc$call$t$inert.gain[1:6]) / sum(res.hcpc$call$t$inert.gain) * 100

table(res.hcpc$data.clust$clust) #nombre d'individus en cada cluster
```


## Sobre les variables categoriques que han estat incloses com a suplementaries

Aqui analitzarem la representacio i relacio de les variables categoriques que s'han inclos com a suplementaries en el PCA destinat a la clusteritzacio jerarquica. Aquestes variables han estat les seguents: "y", "loan", "month", "job", "poutcome", "education" i "housing".

En un primer output basat en el *test chi2* veiem rapidament quines d'aquestes variables discretes suplementaries estan significativament (p-value < 0.05) relacionades globalment amb la particio de clusters establerta. Les variables "month" i "poutcome" tenen un p-valor tan baix que R no el pot representar i ens el marca com a 0; de la mateixa manera, les variables "y(target)", "job", "education" i "housing" estan tambe relacionades amb el particionament seleccionat.

En un segon output desglosat per numero de cluster veiem la sobrerepresentacio i infrarepresentacio de diferents categories en els diferents clusters, ajudant aixi a caracteritzar els diferents grups formats. La presentacio de les dades es la mateixa que la mostrada en el catdes pero amb el numero de cluster com a variable fixada, per tant seran interpretades de la mateixa manera descrita en el primer deliverable.
En una primera **descripcio general**, podem veure com els clusters 1 i 2, i en menor mesura el 3, tenen una sobrerepresentacio d'acceptacio de producte financer. Pel que fa a la resta de clusters, tenen una infrarepresentacio del mateix. El 71% d'acceptacions del producte financer es troben als 3 primers clusters, mentres que el 29% restant es troben als altres 4. Cada cluster a mes, te un lleuger esbiaix en certes catergoreis professionals i d'educacio.
El **primer cluster** es troba caracteritzat per una immensa sobrerepresentacio dels clients amb acceptacio d'una campanya anterior (poutcome-success es un 86% dins el cluster 1 respecte un 3% global); aixo es tradueix tambe en que el 97% d'individus que havien acceptat anteriorment un producte estan situats en aquest cluster. El **segon cluster** es troba sobrerepresentat pels individus retirats (27% respecte un 4% global), el 41% dels quals pertanyen a aquest cluster. També trobem que mes de la meitat de trucades realitzades als mesos d'octubre, setembre i desembre son classificades dins del cluster numero 2. A mes a mes, el segon i en especial el **tercer cluster** (59% dels poutcome-failure pertanyen a aquest) es troben forca sobrerepresentats per individus que anteriorment no van acceptar una campanya (pero aquesta si). Tambe inclouen una sobrerepresentacio d'individus housing-yes. Aquest tercer cluster compren a mes una sobrerepresentacio dels mesos d'abril, maig i marc.
El 99.7% d'individus del **quart cluster** van ser contactats el mes de novembre, el que es tradueix en una immensa sobrerepresentacio en aquest grup, que a mes no va acceptar el producte financer (97.0%).
El **cinque cluster**, **sise cluster** i **sete cluster** estan formats integrament per individus dels quals no es te informacio d'exit o fracas en contactes de campanyes anteriors. El cinque cluster te una sobrerepresentacio dels mesos agost i maig; mentres que el sise i sete clusters la tenen dels mesos juliol i juny. Aquests dos ultims clusters tenen a mes una sobrerepresentacio housing-no (i infra de housing-yes), essent el sete cluster lleugerament diferent del sise pel fet de contenir tambe una sobrereprentacio de l'agost i una major infrarepresentacio d'acceptacio del producte financer.
```{r}
# Factors globally related to clustering partition:
res.hcpc$desc.var$test.chi2
# Categories over/under represented in each cluster:
res.hcpc$desc.var$category
```


## Sobre les variables quantitatives (numeriques)

A continuacio es realitzara una altra descripcio dels diferents clusters formats pero basant-nos en les variables quantitatives (numeriques), les quals han estat utilitzades en el PCA. En el primer output es poden veure les que han estat "p-provades" com a globalment relacionades amb la clusteritzacio, mentres que el detall es pot veure en el segon output.

El **primer cluster** esta caracteritzat per individus (sempre respecte la mitja global) mes contactats en campanyes anteriors (previous) i menys en l'actual (campaign); aixi com individus que han estat contactats molt mes recentment (pdays). La duracio de les trucades en aquest cluster esta 35 segons per sobra la mitja global, aixi com tambe podem veure lleugers esbiaixos en els indicadors socioeconomics (valors baixos de euribor3m, emp.var.rate, nr.employed i cons.conf.idx). El **segon cluster** te una mitjana d'edat 12 anys per sobre la mitjana global, si be tambe una major desvacio estandard dins la categoria; a part d'un esbiaix similar a l'anterior amb els indicadors socioeconomics. El **tercer cluster** es similar al cluster 2 pero amb una mitja d'edat 4 anys per sota de la global; a mes en aquest grup la duracio de les trucades esta per sobra la mitja per 14 segons.
Els quatre altres clusters contenen nomes individus els quals no han estat contactats abans per cap altra campanya (mitja de pdays=19.0 amb un sd de 0) i els seus indicadors socioeconomics tenen un comportament similar en l'esbiaix. El **quart cluster** pero, a diferencia dels altres tres, no mostra una mitja de 0.0 en la variable "previous", el que fa pensar que aquests individus han estat contactat abans pero no necessariament per a una campanya d'un producte. La duracio en aquest cluster es 30 segons per sota la mitja global. Entre els **cinque cluster** i **sise cluster** la diferencia principal esta en l'edat, que que el cinque agrupa individus per sobre la mitja i el sise per sota. Per ultim, el **sete cluster** destaca per a una mitja de duracio de les trucades extremadament curta (65 segons per sota la mitja global), aixi com per un numero de vegades que l'individu ha estat contactat en l'actual campanya molt per sobre de la mitja global (11.3 respecte 2.5).
```{r}
# Numeric (quantitative) variables globally related to clustering partition:
res.hcpc$desc.var$quanti.var
res.hcpc$desc.var$quanti
```


## Descripcio dels clusters mitjancant individus

Aqui descrivim els clusters mitjancant els individus, concretament ens centrarem en els individus que estan al centre de gravetat del cluster (para-parangons) i els que estan mes allunyats de la resta de clusters, es a dir, els mes propis del cluster en questio i menys dels altres (dist-especifics). En les seguents grafiques es poden veure representats en blau els parangons i en taronja els individus especifics per a cada cluster de la classificacio.
```{r}
# Description of the clusters by individuals:
names(res.hcpc$desc.ind)

res.hcpc$desc.ind$para #parangons of each clusters
res.hcpc$desc.ind$dist #specific individuals

#Characteristic individuals - as many as clusters
para1<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$para[[1]]))
para2<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$para[[2]]))
para3<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$para[[3]]))
para4<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$para[[4]]))
para5<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$para[[5]]))
para6<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$para[[6]]))
para7<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$para[[7]]))

dist1<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$dist[[1]]))
dist2<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$dist[[2]]))
dist3<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$dist[[3]]))
dist4<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$dist[[4]]))
dist5<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$dist[[5]]))
dist6<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$dist[[6]]))
dist7<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$dist[[7]]))

df$clust<-factor(res.hcpc$data.clust$clust)

#cluster as variable suplementaria
res.pca<-PCA(df[,c("duration", "clust", vars_con)], quanti.sup=1,quali.sup=2,ncp=4, graph=FALSE)

#? habillage
#color the individuals among a categorical variable (give the number/name of the categorical variable)

plot.PCA(res.pca, label="none", invisible="quali", title="Characteristic  individuals - Cluster 1")
#pintar "para" del cluster 1
points(res.pca$ind$coord[para1,1], res.pca$ind$coord[para1,2], col="blue", cex=2, pch=16)
#pintar "dist" del cluster 1
points(res.pca$ind$coord[dist1,1], res.pca$ind$coord[dist1,2], col="orange", cex=2, pch=16)

plot.PCA(res.pca, label="none", invisible="quali", title="Characteristic  individuals - Cluster 2")
points(res.pca$ind$coord[para2,1], res.pca$ind$coord[para2,2], col="blue", cex=2, pch=16)
points(res.pca$ind$coord[dist2,1], res.pca$ind$coord[dist2,2], col="orange", cex=2, pch=16)

plot.PCA(res.pca, label="none", invisible="quali", title="Characteristic  individuals - Cluster 3")
points(res.pca$ind$coord[para3,1], res.pca$ind$coord[para3,2], col="blue", cex=2, pch=16)
points(res.pca$ind$coord[dist3,1], res.pca$ind$coord[dist3,2], col="orange", cex=2, pch=16)

plot.PCA(res.pca, label="none", invisible="quali", title="Characteristic  individuals - Cluster 4")
points(res.pca$ind$coord[para4,1], res.pca$ind$coord[para4,2], col="blue", cex=2, pch=16)
points(res.pca$ind$coord[dist4,1], res.pca$ind$coord[dist4,2], col="orange", cex=2, pch=16)

plot.PCA(res.pca, label="none", invisible="quali", title="Characteristic  individuals - Cluster 5")
points(res.pca$ind$coord[para5,1], res.pca$ind$coord[para5,2], col="blue", cex=2, pch=16)
points(res.pca$ind$coord[dist5,1], res.pca$ind$coord[dist5,2], col="orange", cex=2, pch=16)

plot.PCA(res.pca, label="none", invisible="quali", title="Characteristic  individuals - Cluster 6")
points(res.pca$ind$coord[para6,1], res.pca$ind$coord[para6,2], col="blue", cex=2, pch=16)
points(res.pca$ind$coord[dist6,1], res.pca$ind$coord[dist6,2], col="orange", cex=2, pch=16)

plot.PCA(res.pca, label="none", invisible="quali", title="Characteristic  individuals - Cluster 7")
points(res.pca$ind$coord[para7,1], res.pca$ind$coord[para7,2], col="blue", cex=2, pch=16)
points(res.pca$ind$coord[dist7,1], res.pca$ind$coord[dist7,2], col="orange", cex=2, pch=16)

```

