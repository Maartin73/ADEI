---
output:
  pdf_document: default
  html_document: default
editor_options: 
  chunk_output_type: console
---

# Course Practical Assignment - 2nd Deliverable (21 d'abril del 2019)
## *Josep Clotet Ginovart*
## *Eric Martin Obispo*

# Bank client data
## Description of input variables:

  1. age (numeric)
  2. job : type of job (categorical: 'admin', 'blue-collar', 'entrepreneur', 'housemaid', 'management', 'retired', 'self-employed', 'services', 'student', 'technician', 'unemployed', 'unknown')
  3. marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)
  4. education (categorical:'basic.4y', 'basic.6y', 'basic.9y', 'high.school', 'illiterate', 'professional.course', 'university.degree', 'unknown')
  5. default: has credit in default? (categorical: 'no','yes','unknown')
  6. housing: has housing loan? (categorical: 'no','yes','unknown')
  7. loan: has personal loan? (categorical: 'no','yes','unknown')# related with the last contact of the current campaign:
  8. contact: contact communication type (categorical:'cellular','telephone')
  9. month: last contact month of year (categorical: 'jan', 'feb', 'mar',..., 'nov', 'dec')
  10. day_of_week: last contact day of the week (categorical:'mon','tue','wed','thu','fri')
  11. duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.
  12. campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)
  13. pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)
  14. previous: number of contacts performed before this campaign and for this client (numeric)
  15. poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')# social and economic context attributes
  16. emp.var.rate: employment variation rate - quarterly indicator (numeric)
  17. cons.price.idx: consumer price index - monthly indicator (numeric)
  18. cons.conf.idx: consumer confidence index - monthly indicator (numeric)
  19. euribor3m: euribor 3 month rate - daily indicator (numeric)
  20. nr.employed: number of employees - quarterly indicator (numeric)
  21. y - has the client subscribed a term deposit? (binary: 'yes','no')

# Loading packages:
```{r, include=FALSE}
# Required Packages: to be increased over the course
requiredPackages <- c("car","knitr","ggplot2","FactoMineR","missMDA","mvoutlier","chemometrics", "factoextra")
missingPackages <- requiredPackages[!(requiredPackages %in% installed.packages()[,"Package"])]

if(length(missingPackages)) install.packages(missingPackages)
lapply(requiredPackages, require, character.only = TRUE)

```

# Load data from Deliverable 1:
```{r}
dirwd<-"D:/Users/Usuari/Documents/ADEIpractica"
#dirwd<-"D:/Documents/GitHub/ADEI"
setwd(dirwd)

load( paste0(dirwd, "/bank-additional/Bank5000_validated.RData") )
summary(df)
```



# CORRESPONDENCE ANALYSIS (CA)
Realitzarem un analisi amb taules de correspondencia i mapes de factors entre la variable numerica target duracio discretitzada en 4 nivells (corregit de l'entrega 1) i diversos factors que hem trobat que tenen una correspondencia significativa.

Primer veiem com la duracio de la trucada no te cap relacio amb el job de l'individu, ja que no podem rebutjar la hipotesi *H0: f.duration no te cap relacio amb la variable job* amb el valor p obtingut en el Chi Square test. 
Com mes aprop surten al grafic les categories d'ambdues variables analitzades, mes relacionades estan. En aquesta comparacio, com s'acaba de comentar, no es pot extreure res significatiu, mes enlla que potser les categories job-unemployed i job-self-employed van mes per lliure.
```{r}
# H0: f.duration no te cap relacio amb variable job
chisq.test( table( df$job, df$f.duration) )
# CA - f.duration vs variable job
res.ca<-CA( table( df$job, df$f.duration ) )
lines(res.ca$row$coord[,1], res.ca$row$coord[,2], col="darkblue")
lines(res.ca$col$coord[,1], res.ca$col$coord[,2], col="darkred")
```

Ara testejarem la mateixa hipotesi i mostrarem el mateix mapa de factors pero amb altres categories factor que si que obtindrem que tenen una relacio significativa. El primer cas es l'epoca de l'any **f.season** en la qual es realitza la trucada (p valor = 2.506e-07).
Comparant el profile de la taula de contingencia de proporcions per fila amb el profile marginal de la duracio veiem com hi ha un 28,5% de trucades amb duracions molt curtes a l'estiu respecte un 25% de trucades amb duracions curtes en tot l'any. D'altra banda, hi ha per sobre d'un 27% de trucades amb duracions llargues a la primavera, respecte un 25% de trucades en la mateixa duracio en tot l'any.
Si comparem el profile de la taula de contingencia de proporcions per columna amb el profile marginal de la f.season veiem com el 42.5% de trucades es realitzen a la primavera, i en canvi mes d'un 46% de trucades corresponen a la primavera i a duracions llargues. A mes, el 43.7% de trucades es realitzen a l'estiu, i nomes prop d'un 40% de trucades corresponen a l'estiu i a duracions llargues.
Aquesta mateixa informacio es pot veure representada en un mapa de factors de dues dimensions. Agafant nomes la primera dimensio ja seria suficient per a representar un 98.9% de la variancia del conjunt de les dades (Kaiser: take as many dimensions as eigenvalue > mean of eigenvalues).
```{r}
chisq.test( table( df$f.season, df$f.duration) )

#Row/Column profile
prop.table( table(df$f.season, df$f.duration), 1 ) #1->per files
#Marginal Row/Column profile
prop.table( table(df$f.duration)) #1->per files

prop.table( table(df$f.season, df$f.duration), 2 ) #2->per columnes
prop.table( table(df$f.season)) #2->per columnes


res.ca<-CA( table( df$f.season, df$f.duration) )
attributes(res.ca); res.ca$eig #valors eig no normalitzats!
mean(res.ca$eig[,1]) #Kaiser: take as many dimensions as eigenvalue > mean of eigenvalues
#En una taula de correspondencies simples podem tenir m?xim tantes 
#dimensions com categories d'una variable menys 1! 
#f.season te 3 categories -> -1 -> 2 dimensions!!

#La inercia total ens indica com de relacionades estan les dues variables, com mes proxim el valor a 0, menys relacionades estan!
sum(res.ca$eig[,1])

#Coordenades:
#res.ca$row #files son la f.season!
#res.ca$col #columnes son la duration!

```

El segon cas en el qual obtenim una relacio significativa (p valor = 1.203e-07) es el valor de l'euribor **f.euribor3m**, el qual es un indicador trimestral.
Comparant el profile de la taula de contingencia de proporcions per fila amb el profile marginal de la duracio veiem com hi ha un 30.8% de trucades amb duracions molt curtes quan l'euribor te un valor alt, respecte un 25% de trucades amb duracions sense tenir en compte la fluctuacio de l'indicador. De la mateixa manera, quan el valor de l'euribor es baix, hi ha major % de trucades que acaben amb duracions relativament altes.
Si comparem el profile de la taula de contingencia de proporcions per columna amb el profile marginal de f.euribor3m veiem com el 22.8% de trucades es realitzen amb un euribor molt alt, i en canvi un 28.0% de trucades corresponen a un euribor alt i a duracions molt curtes.
A mes, mirant el mapa de factors podem veure aquesta mateixa informacio de manera grafica. Si ens centrem en la 1a dimensio del grafic (que representa un 89% de la variancia del conjunt de les dades), podem observar com hi ha una tendencia similar en ambdues variables (tot i que les duracions extremadament llargues trenquen una molt bona correlacio del 1r eix). Tambe veiem com les categories f.euribor3m-(4.96,5] i f.duration-[5,101] estan molt relacionades ja que es troben molt proximes en el mapa de factors; aixi com tambe les categories f.euribor3m-[0.635,1.33] i f.duration-(177,316].
(Kaiser: take as many dimensions as eigenvalue > mean of eigenvalues, el que equival a agafar 1 sola dimensio).
```{r}
chisq.test( table( df$f.euribor3m, df$f.duration) )

#Row/Column profile
prop.table( table(df$f.euribor3m, df$f.duration), 1 ) #1->per files
#Marginal Row/Column profile
prop.table( table(df$f.duration)) #1->per files

prop.table( table(df$f.euribor3m, df$f.duration), 2 ) #2->per columnes
prop.table( table(df$f.euribor3m)) #2->per columnes


res.ca<-CA( table( df$f.euribor3m, df$f.duration) )
lines(res.ca$row$coord[,1], res.ca$row$coord[,2], col="darkblue")
lines(res.ca$col$coord[,1], res.ca$col$coord[,2], col="darkred")

attributes(res.ca); res.ca$eig #valors eig no normalitzats!
mean(res.ca$eig[,1]) #Kaiser: take as many dimensions as eigenvalue > mean of eigenvalues
#En una taula de correspondencies simples podem tenir maxim tantes 
#dimensions com categories d'una variable menys 1! 
#f.euribor3m te 4 categories -> -1 -> 3 dimensions!!

#La inercia total ens indica com de relacionades estan les dues variables, com mes proxim el valor a 0, menys relacionades estan!
sum(res.ca$eig[,1])

#A vegades va be eliminar algunes categories amb pocs individus d'una variable per a poder veure millor les possibles relacions!
```



# PRINCIPAL COMPONENT ANALYSIS (PCA)

Primerament realitzem un PCA sobre les variables continues de la nostra mostra de dades, on la variables "duration" ha de ser suplementaria, ja que es tracta de la variable target!

## Eigenvalues and dominant axes

El summary ens permet veure els 9 diferents eigenvalues obtinguts amb aquest PCA, amb les seves dades corresponents de percentatges de variancia del conjunt de les dades que respresenten. Segons el criteri de Kaiser, que diu que s'han de descartar les dimensions amb valors eig normalitzats per sota d'1, hauriem d'agafar les 3 primeres dimensions per a una bona representacio del conjunt de dades. 
Essent flexibles amb el criteri de Kaiser, podriem agafar tambe la quarta dimensio, la qual te una variancia del 0.9656, amb un valor molt proxim a 1. La incorporacio d'aquesta nova dimensio ens donaria una variancia acumulada del 81%, obtenint d'aquesta manera una variancia acumulada per sobre el 80%.
Per ?ltim, si ens basem en la regla del colze (llegurament subjectiva), i l'apliquem sobre el grafic dels eigenvalues i %variancies obtingut amb les llibreries *ggplot*, hauriem d'agafar les 3 primeres dimensions.
```{r}
vars_con<-names(df)[c(1, 11:14, 16:20)]; vars_con #variables continues
vars_dis<-names(df)[c(2:10, 15, 21, 25, 27:36)] #variables discretes

# PCA:
res.pca<-PCA( df[, vars_con], quanti.sup=2, graph=FALSE) #"duration" com a suplementaria
#nb.dec: number of decimal printed
#ncp: number of dimensions printed
summary(res.pca, nb.dec=2, ncp=5, nbind=0)
#GGPLOT: Use modern ggplot facilities per la regla de l'ultim colze:
#at some point the marginal gain will drop, giving an angle in the graph
fviz_eig(res.pca, addlabels=TRUE)
```

## Individuals point of view
Pintem primer el mapa de factors dels individus de les dues primeres dimensions (70% de la variancia del conjunt de dades) i etiquetem amb el numero d'individu els 15 mes contributius.
A continuacio mostrem per a cadascun dels dos primers eixos, les coordenades i el registre complet d'aquests 3 individus mes contributius.
Es fa exactament el mateix amb els individus mes ben representats (cos2) en les dues primeres dimensions.
```{r}
#nomes pinta les etiquetes dels 15 individus mes contributius!
plot(res.pca, choix="ind", cex=0.75, col.ind="black", select="contrib 15")
#3 individus mes contributius al 1r eix:
contrib<-sort(res.pca$ind$contrib[,1], decreasing=TRUE)[1:3]; contrib
df[c(names(contrib)), ]
#3 individus mes contributius al 2n eix:
contrib<-sort(res.pca$ind$contrib[,2], decreasing=TRUE)[1:3]; contrib
df[c(names(contrib)), ]


#nomes pinta les etiquetes dels 15 individus mes contributius!
plot(res.pca, choix="ind", cex=0.75, col.ind="black", select="cos2 15")
#3 individus mes ben representats al 1r eix:
repr<-sort(res.pca$ind$cos2[,1], decreasing=TRUE)[1:3]; repr
#df[c(names(repr)), ]
#3 individus mes ben representats al 2n eix:
repr<-sort(res.pca$ind$cos2[,2], decreasing=TRUE)[1:3]; repr
#df[c(names(repr)), ]

```

## Interpretation of the PCA
En el mapa de factors de les variables (2D, primeres dues dimensions) es pot observar en blau la variable "duration" com a suplementaria, la qual surt quasi centrada, el que vol dir que les variables vars_con utilitzades en el PCA no ens ajuden a dir res o predir el valors de la variable target. La variable previous (numero de contactes en campanyes antigues) esta relacionada inversament amb pdays (dies que feia que no es trucava el client per altres campanyes), ja que que com es pot veure en el grafic, ambdues fletxes apunten oposadament. Sembla ser tambe que tots els indicadors socioeconomics (a excepcio una mica de cons.conf.idx) apunten en la mateixa direccio, el que vol dir que estan relacionats entre ells i contribueixen d'una manera similar als eixos.
Es pot veure el % de contribucio de les variables a les tres primeres dimensions mitjancant una eina de la llibreria *ggplot*, on es veu com basicament els indicadors socioeconomics i les variables "previous", "campaign" i "age" son les variables numeriques que mes han contribuit.
El summary ens permet veure tambe de forma numerica la contribucio (ctr) de cadascuna de les variables en els 4 primers eixos, aix? com la qualitat de la representacio (cos2) de les mateixes en cadascun dels eixos. Si be s'acaben de descriure les variables mes contributives, les que estan millor representades (cos2 mes proxim a 1) en el primer eix son euribor3m, emp.var.rate i nr.employed; i en el segon eix son pdays, previous i cons.conf.idx.
Un l'ultim mapa de factors de variables observem els eixos de les dimensions 3 i 4, les quals representen aproximadament un 11% de la variancia de les dades cadascuna.
```{r}
# PCA:
res.pca<-PCA( df[, vars_con], quanti.sup=2, graph=FALSE) #"duration" com a suplementaria

plot.PCA(res.pca, choix = c("var") ) #variables factor map

#GGPLOT contribution of variables
#fviz_pca_var(res.pca)
fviz_contrib(res.pca, choice="var", axes=1:3)+theme_bw()

summary(res.pca, nb.dec=2, ncp=4, nbind=0)

#veure eixos 3 i 4:
res.pca<-PCA(df[, vars_con], quanti.sup=2, axes=3:4)
```

Com que es dificil extreure conclusions a partir nomes de les variables numeriques, en el grafics seguents es pot observar el posicionament de les dues variables suplementaries "f.duration" i "f.euribor3m" en el mapa de factors dels individus. 
En el cas de f.duration, si es mira al mapa de factors ampliat on nomes es representa aquesta variable, sembla ser que te una tendencia a creixer cap al 2n i 3r quadrant composat per les dues primeres dimensions.
En el cas de f.euribor3m, de la mateixa manera, tambe es pot trobar un progressio de les dades al llarg del primer eix, ja que el valor de l'euribor3m augmenta amb el valor de la primera dimensio de les dades.
```{r}
par(mfrow=c(1,1))

#ara afegim dues variables suplementaries!
res.pca<-PCA( df[, c("f.duration", vars_con) ], quanti.sup=3, quali.sup=1, graph = FALSE ) 
plot.PCA(res.pca, choix = c("ind") )
#Unir punts de variables suplementaries en el factor map per a una bona representacio:
plot.PCA(res.pca, choix="ind", invisible="ind")
lines(res.pca$quali.sup$coord[1:2, 1:2], col="blue", lwd="2")
lines(res.pca$quali.sup$coord[2:3, 1:2], col="blue", lwd="2")
lines(res.pca$quali.sup$coord[3:4, 1:2], col="blue", lwd="2")

res.pca<-PCA( df[, c("f.euribor3m", vars_con) ], quanti.sup=3, quali.sup=1, graph = FALSE ) 
plot.PCA(res.pca, choix = c("ind") )
plot.PCA(res.pca, choix="ind", invisible="ind")
lines(res.pca$quali.sup$coord[1:2, 1:2], col="blue", lwd="2")
lines(res.pca$quali.sup$coord[2:3, 1:2], col="blue", lwd="2")
lines(res.pca$quali.sup$coord[3:4, 1:2], col="blue", lwd="2")


#Fer el mateix amb la variable duration (factoritzada?) i veure el nuvol de punts i si es pot unir pq segueix alguna progressio!!!
```

```{r, include=FALSE}
#valors v.test >1,96 ens indiquen que la categoria ens aporta alguna cosa!
#   --> son les que ens podriem quedar en un subconjunt i que fos l'utlitzat a l'hora de representar graficament i triar els eixos (pels deliverables no cal aixi!).
```



# K-Means Classification (Partitioning - Supervised learning)

K-means es una de les diverses tecniques de clustering. Com a tota tecnica de clustering, l'objectiu es realitzar subgrups d'observacions amb l'objectiu d'obtenir agrupacions amb caracteristiques similars i que es diferenciin de les carasteriques per les que destaquen els altres grups, es a dir amb una variancia intra-cluster el més minima possible i intentant maximitzar la variacio inter-cluster.

En el nostre cas, em escollit treballar amb 4 dimensions, per tal de reduir soroll innecessary, i 6 clusters.

Del resultats obtingut per kmeans en podem extreure diverses conclusions. En primer lloc la taula de clusters ens mostra cada observació amb el seu nombre de cluster assignaat. Al realitzar un sumari podem veure la distribució de les observacions a través dels diferents clusters. Withinss, corresponent a la inercia intra-cluster, s'obte a traves de la suma de quadrats dins del clúster. Obtenim un valor per acada un dels clusters, com més baix es el nombre obtingut més significativa es la homegeinitat dels clusters. Per altra banda, Betweenss o inercia inter-cluster, es la suma de cuadrats entre clusters, la mitjana de distàncies entre els centres de clústers. La obtencio d'un valor alt ens demostra la heterogeneitat de les agrupacions. 

Tot.withinss correspon a la suma de totes les distancies intra-cluster i totss a la suma de les distancies intra-cluster i inter-cluster. Per acabar, la fraccio obtinguda de betweenss i totss ens mostra que unicament amb els centres de gravetat estem obtenint una representacio del 77% de les dades, una xifra realment bona que ens indica que el nombre de clusters escollit es l'indicat.

```{r}
dclu<-res.pca$ind$coord[,1:4]

kcla<-kmeans(dclu, 6);summary(kcla) 

table(kcla$cluster)

kcla$withinss 

kcla$betweenss

kcla$tot.withinss

kcla$totss 

kcla$betweenss/kcla$totss

```

##Eleccio del nombre de clusters
Ha sigut per mitjà d'aquest algoritme que hem determinat quin es el valor de k més indicat. l'algoritme ens mostra les distancies intra-clusters per a cada un dels valors de k, ens interesa trobar un valor de k on la distancia intra-cluster sigui el menor possible. A mesura que s'incrementa el nombre de k la distancia intra-cluster es veu reduida, no podem agafar el valor amb la distancia mes petita, el mes indicat seria agafar aquell valor de k on la la funcio para de decreixer de manera significativa. Em determinat que aquest valor correspon a k=6. 
```{r}
wss <- sum(kmeans(dclu,centers=1)$withinss)

# We take iteration 2 to 15
for (i in 2:15) wss[i] <- sum(kmeans(dclu,centers=i)$withinss)

# We plot the 15 withinss values. One for each k
plot(1:15, wss, type="b", xlab="Number of Clusters",ylab="Within groups sum of squares")
```

##Descripcio dels clusters
```{r}
numcl<-6
df$KM<-numcl
df[names(kcla$cluster),"KM"]<-kcla$cluster
df$f.KM<-factor(df$KM, labels = c("KM1", "KM2", "KM3", "KM4", "KM5", "KM6"))
names(df)
varskm<-names(df[c(1:21)])
vars<-c(varskm, "f.KM")
targ<-which(vars == "f.KM")

catdes(df[,vars],targ)

```
##Cluster1
En aquest cluster podem observar podem apreciar com el nombre de contactes en campanyes previes es troba per sobre de la mitjana total. També podem veure que la edad mitjana dins el cluster es 4 anys menor a la mitjana global i que els valors socio-economics mostren condicions bastant semblants respecte a el conjunt global de dades, a excepcio del euribor que mostra unes condicions mes faborables.

La duracio de les trucades i els dies transcorreguts de l'ultim contacte difereixen lleugerament de la mitjana global, en aquest cas pero no ens mostren una diferencia significativa com per poder-los considerar com a factors determinants dins el cluster.




# Hierarchical Clustering (Unsupervised learning)
Aquest punt compren la realitzacio d'una clusteritzacio aglomerativa jerarquitzada dels individus. HCPC de la llibreria FactoMineR utilitza les distancies de entre clusters diferents, per tal de minimitzar la inercia inter-cluster.

La primera de les comandes esta comentada ja que requereix l'interacio de l'usuari per a triar per on tallar l'arbre de clusters que es mostra a l'usuari. Despres d'estar interactuant amb diferents opcions de numero de clusters, s'ha decidit finalment agafar nb.clust = 7, tal i com es pot veure a continuacio. Es mostren els grafics corresponents a l'arbre el qual s'ha tallat a l'altura de 7 clusters, aix? com el mapa de factors de les dues primeres dimensions del PCA.
```{r}
#PCA calculat amb 4 significant axes:
vars_con<-names(df)[c(1, 12:14, 16:20)]; vars_con
res.pca<-PCA( df[, c("duration", "y", vars_con) ], quanti.sup=1, quali.sup=2, ncp=4, graph=FALSE )

#res.hcpc<-HCPC(res.pca, order=TRUE)

res.hcpc<-HCPC(res.pca, nb.clust=7, order=TRUE, graph=FALSE); res.hcpc
attributes(res.hcpc)

plot.HCPC(res.hcpc, choice="tree")

plot.HCPC(res.hcpc, choice="map")
fviz_cluster(res.hcpc)
```

El guanys (d'1 a 2 clusters, de 2 a 3, de 3 a 4, etc.) d'inercia es poden observar en negre a la figura inferior, on tambe es pot veure la relacio entre altres nivells de tall i els seus guanys. Els valors *within* ens mostren la inercia dins de cada cluster, que si fos un sol cluster (1) seria la total del conjunt de dades, la qual equival a la suma de tots els guanys d'inercies *inert.gain*. Amb la seleccio de 6 clusters que hem agafat estariem obtenint una representacio de les dades del 80.4%, la qual es molt bona! Finalment, tamb? podem veure la distribucio en nombre d'individus en els diferents clusters.
```{r}
plot.HCPC(res.hcpc, choice="bar")

res.hcpc$call$t$inert.gain[1:6]
sum(res.hcpc$call$t$inert.gain)

res.hcpc$call$t$within[1:7]

sum(res.hcpc$call$t$inert.gain[1:6]) / sum(res.hcpc$call$t$inert.gain) * 100 #6 clusters corresponen al 80.4% d'inercia

table(res.hcpc$data.clust$clust) #nombre d'individus en cada cluster
```


## Sobre les variables categoriques que han estat incloses com a suplementaries
TODO (i canviar var suplementaries)
```{r}
# Factors globally related to clustering partition:
res.hcpc$desc.var$test.chi2
# Categories over/under represented in each cluster:
res.hcpc$desc.var$category #veiem com hi ha clusters que tenen sobrerepresentacio d'acceptacio del producte financer!

```


## Sobre les variables quantitatives (numeriques)
TODO
```{r}
# Numeric (quantitative) variables globally related to clustering partition:
res.hcpc$desc.var$quanti.var
res.hcpc$desc.var$quanti
```


## Descripcio dels clusters mitjancant individus
Aqui descrivim els clusters mitjancant els individus, concretament ens centrarem en els individus que estan al centre de gravetat del cluster (para-parangons) i els que estan mes allunyats de la resta de clusters, es a dir, els mes propis del cluster en questio i menys dels altres (dist-especifics). En les seguents grafiques es poden veure representats en blau els parangons i en taronja els individus especifics per a cada cluster de la classificacio.
```{r}
# Description of the clusters by individuals:
names(res.hcpc$desc.ind)

res.hcpc$desc.ind$para #parangons of each clusters
res.hcpc$desc.ind$dist #specific individuals

#Characteristic individuals - as many as clusters
para1<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$para[[1]]))
para2<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$para[[2]]))
para3<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$para[[3]]))
para4<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$para[[4]]))
para5<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$para[[5]]))
para6<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$para[[6]]))
para7<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$para[[7]]))

dist1<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$dist[[1]]))
dist2<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$dist[[2]]))
dist3<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$dist[[3]]))
dist4<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$dist[[4]]))
dist5<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$dist[[5]]))
dist6<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$dist[[6]]))
dist7<-which(rownames(res.pca$ind$coord)%in%names(res.hcpc$desc.ind$dist[[7]]))

df$clust<-factor(res.hcpc$data.clust$clust)

res.pca<-PCA(df[,c("duration", "clust", vars_con)], quanti.sup=1,quali.sup=2,ncp=4, graph=FALSE) #cluster as variable suplementaria

#? habillage
#color the individuals among a categorical variable (give the number/name of the categorical variable)

plot.PCA(res.pca, label="none", invisible="quali", title="Characteristic  individuals - Cluster 1")
#pintar "para" del cluster 1
points(res.pca$ind$coord[para1,1], res.pca$ind$coord[para1,2], col="blue", cex=2, pch=16)
#pintar "dist" del cluster 1
points(res.pca$ind$coord[dist1,1], res.pca$ind$coord[dist1,2], col="orange", cex=2, pch=16)

plot.PCA(res.pca, label="none", invisible="quali", title="Characteristic  individuals - Cluster 2")
points(res.pca$ind$coord[para2,1], res.pca$ind$coord[para2,2], col="blue", cex=2, pch=16)
points(res.pca$ind$coord[dist2,1], res.pca$ind$coord[dist2,2], col="orange", cex=2, pch=16)

plot.PCA(res.pca, label="none", invisible="quali", title="Characteristic  individuals - Cluster 3")
points(res.pca$ind$coord[para3,1], res.pca$ind$coord[para3,2], col="blue", cex=2, pch=16)
points(res.pca$ind$coord[dist3,1], res.pca$ind$coord[dist3,2], col="orange", cex=2, pch=16)

plot.PCA(res.pca, label="none", invisible="quali", title="Characteristic  individuals - Cluster 4")
points(res.pca$ind$coord[para4,1], res.pca$ind$coord[para4,2], col="blue", cex=2, pch=16)
points(res.pca$ind$coord[dist4,1], res.pca$ind$coord[dist4,2], col="orange", cex=2, pch=16)

plot.PCA(res.pca, label="none", invisible="quali", title="Characteristic  individuals - Cluster 5")
points(res.pca$ind$coord[para5,1], res.pca$ind$coord[para5,2], col="blue", cex=2, pch=16)
points(res.pca$ind$coord[dist5,1], res.pca$ind$coord[dist5,2], col="orange", cex=2, pch=16)

plot.PCA(res.pca, label="none", invisible="quali", title="Characteristic  individuals - Cluster 6")
points(res.pca$ind$coord[para6,1], res.pca$ind$coord[para6,2], col="blue", cex=2, pch=16)
points(res.pca$ind$coord[dist6,1], res.pca$ind$coord[dist6,2], col="orange", cex=2, pch=16)

plot.PCA(res.pca, label="none", invisible="quali", title="Characteristic  individuals - Cluster 7")
points(res.pca$ind$coord[para7,1], res.pca$ind$coord[para7,2], col="blue", cex=2, pch=16)
points(res.pca$ind$coord[dist7,1], res.pca$ind$coord[dist7,2], col="orange", cex=2, pch=16)

```

